{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Self Contained Genetic Programming.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP1ZtZ4o1HSs1KozQHkmGxp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parkerburchett/Numerai/blob/main/Self_Contained_Genetic_Programming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2REW-cDffPz3",
        "outputId": "6bbb5627-3d23-4133-f554-45f925a7e8d5"
      },
      "source": [
        "!pip install numerapi\n",
        "!pip install gplearn\n",
        "\n",
        "for batch in range(100): # create log files\n",
        "  with open(f'/log_{batch}.pkl','x') as out:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numerapi\n",
            "  Downloading numerapi-2.6.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from numerapi) (2018.9)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from numerapi) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from numerapi) (2.23.0)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from numerapi) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from numerapi) (2.8.1)\n",
            "Requirement already satisfied: tqdm>=4.29.1 in /usr/local/lib/python3.7/dist-packages (from numerapi) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.0->numerapi) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->numerapi) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (2.10)\n",
            "Installing collected packages: numerapi\n",
            "Successfully installed numerapi-2.6.0\n",
            "Collecting gplearn\n",
            "  Downloading gplearn-0.4.1-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 249 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from gplearn) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.7/dist-packages (from gplearn) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->gplearn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->gplearn) (1.4.1)\n",
            "Installing collected packages: gplearn\n",
            "Successfully installed gplearn-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSr_iuo4fNMr",
        "outputId": "15cc9055-b119-4910-ae9c-e35a4211c1e7"
      },
      "source": [
        "%%time\n",
        "import numerapi\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import pickle\n",
        "from gplearn.functions import make_function\n",
        "from gplearn.genetic import SymbolicTransformer\n",
        "\n",
        "def create_function_set():\n",
        "  \"\"\"\n",
        "    The individual Atomic Functions to be used as the parts of the linear transformations\n",
        "  \"\"\"\n",
        "  tanh = make_function(np.tanh,'tanh', arity=1)\n",
        "  divide_by_two = make_function(lambda col: np.divide(col,2),'divide_by_two', arity=1)\n",
        "  #average = make_function(lambda a,b: np.average(a,b) , 'average', arity=2) # broken. unsure why.\n",
        "  function_set = ['add', 'sub', 'mul', 'div','neg', tanh, divide_by_two] \n",
        "  return function_set\n",
        "\n",
        "def correlation(predictions, targets):\n",
        "    ranked_preds = predictions.rank(pct=True, method=\"first\")\n",
        "    return np.corrcoef(ranked_preds, targets)[0, 1]\n",
        "\n",
        "def score(df): # copied from example.py from Numerai\n",
        "    return correlation(df['prediction'], df['target'])\n",
        "\n",
        "def atomic_program_evaluation(atomic_program, valid_X, valid_y):\n",
        "  \"\"\"\n",
        "      Pass this function a program and it returns a dict of the evaluation of the program.\n",
        "      'program_obj': the atomic program object\n",
        "      'program_str': String repersentation of the program\n",
        "      'corr':  corr on the unseen validation data for this round.\n",
        "  \"\"\"\n",
        "  res = pd.DataFrame()\n",
        "  res['prediction'] = atomic_program.execute(valid_X.values)\n",
        "  res['target'] = valid_y.values  # defined globally\n",
        "  outcome = dict()\n",
        "  outcome['program_obj'] = atomic_program\n",
        "  outcome['program_str'] = str(atomic_program)\n",
        "  outcome['corr'] = score(res)\n",
        "  return outcome\n",
        "\n",
        "def create_new_unfit_symbolic_transformer(function_set:list, feature_cols, verbose=True, simple=False):\n",
        "\n",
        "  if not simple:\n",
        "    new_transformer = SymbolicTransformer(verbose=verbose, # these were choose with no real reason in mind.\n",
        "                            feature_names=feature_cols,\n",
        "                            generations=10,\n",
        "                            metric='spearman',\n",
        "                            parsimony_coefficient =.0005, \n",
        "                            population_size= 5000, \n",
        "                            function_set=function_set,\n",
        "                            n_jobs=-1,\n",
        "                            init_depth = (3,7),\n",
        "                            low_memory=True,\n",
        "                            stopping_criteria = .035,\n",
        "                            tournament_size=200)\n",
        "  else:\n",
        "      new_transformer = SymbolicTransformer(verbose=verbose,\n",
        "                            feature_names=feature_cols,\n",
        "                            generations=3,\n",
        "                            metric='spearman',\n",
        "                            low_memory=True,\n",
        "                            parsimony_coefficient =.0005, \n",
        "                            population_size= 500, \n",
        "                            function_set=function_set,\n",
        "                            n_jobs=-1,\n",
        "                            init_depth = (2,3),\n",
        "                            stopping_criteria = .035,\n",
        "                            tournament_size=50)\n",
        "\n",
        "  return new_transformer #unfit_transformer = create_new_unfit_symbolic_transformer()\n",
        "\n",
        "def setup(): # you cannot pickle the setup.\n",
        "  napi = numerapi.NumerAPI()\n",
        "  current_round = napi.get_current_round()\n",
        "  napi.download_current_dataset(unzip=True)\n",
        "  train_df = pd.read_csv(f'/content/numerai_dataset_{current_round}/numerai_training_data.csv', index_col=0)\n",
        "  tournament_df = pd.read_csv(f'/content/numerai_dataset_{current_round}/numerai_tournament_data.csv', index_col=0)\n",
        "  feature_cols = [c for c in train_df.columns if c.startswith(\"feature\")]\n",
        "  X = train_df[feature_cols]\n",
        "  y = train_df['target']\n",
        "  valid_df = tournament_df[tournament_df[\"data_type\"] == \"validation\"].reset_index(drop = True)\n",
        "  valid_X = valid_df[feature_cols]\n",
        "  valid_y = valid_df['target']\n",
        "  function_set = create_function_set()\n",
        "  return train_df, tournament_df, valid_df, feature_cols, X, y, valid_X, valid_y, function_set\n",
        "\n",
        "\n",
        "def main():\n",
        "  print('in setup')\n",
        "  train_df, tournament_df, valid_df, feature_cols, X, y, valid_X, valid_y, function_set = setup() # takes 2 minutes on colab on high ram\n",
        "  print(\"done with setup\")\n",
        "  def evolve_new_atomic_programs(valid_X, valid_y):\n",
        "    \"\"\"\n",
        "      Defined internally to not have to repass params.\n",
        "    \"\"\"\n",
        "    transformer = create_new_unfit_symbolic_transformer(function_set=function_set, feature_cols=feature_cols, simple=False)\n",
        "    print('now EVOLVING')\n",
        "    transformer.fit(X,y)\n",
        "    return [atomic_program_evaluation(prog, valid_X, valid_y) for prog in transformer] # returns a list of dicts.\n",
        "\n",
        "  for batch in range(2):\n",
        "    print(f'BATCH {batch}')\n",
        "    log_pickle_location = f\"/content/log_{batch}.pkl\"  \n",
        "\n",
        "    #Read already evolved atomic programs from disk.\n",
        "    try:\n",
        "      atomic_programs_file = open(log_pickle_location,'rb')\n",
        "      list_of_atomic_programs = pickle.load(atomic_programs_file)\n",
        "      atomic_programs_file.close()\n",
        "      if type(list_of_atomic_programs) is not list:\n",
        "        raise ValueError() # just to get to except\n",
        "    except:\n",
        "      list_of_atomic_programs = []\n",
        "\n",
        "    # add those atomic programs to your system.\n",
        "    new_atomic_programs = evolve_new_atomic_programs(valid_X, valid_y)\n",
        "    print('you successfully evolved new atomic programs')\n",
        "    list_of_atomic_programs.extend(new_atomic_programs)\n",
        "\n",
        "    print('look at the models you evolved')\n",
        "    for s in new_atomic_programs:\n",
        "      print(s)\n",
        "\n",
        "    # write the new programs to disk.\n",
        "    atomic_programs_file = open(log_pickle_location,'wb') #\n",
        "    pickle.dump(list_of_atomic_programs, atomic_programs_file)\n",
        "    atomic_programs_file.close()\n",
        "    print('after one run  have this many atomic programs')\n",
        "    print(len(list_of_atomic_programs))\n",
        "  \n",
        "\n",
        "    \n",
        "\n",
        "main() # next call there should be 20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "in setup\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-31 22:26:39,547 INFO numerapi.utils: target file already exists\n",
            "2021-07-31 22:26:39,550 INFO numerapi.utils: download complete\n",
            "2021-07-31 22:26:39,553 INFO numerapi.base_api: unzipping file...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done with setup\n",
            "BATCH 0\n",
            "now EVOLVING\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    16.12       0.00367335        7        0.0182351              N/A     33.93m\n",
            "   1     2.92         0.013146        5        0.0212706              N/A     22.54m\n",
            "   2     4.09        0.0163472        9        0.0248213              N/A     20.66m\n",
            "   3     6.40         0.017327       13        0.0276577              N/A     19.06m\n",
            "   4     8.36        0.0182653       15        0.0293495              N/A     15.77m\n",
            "   5     8.94        0.0179872       13        0.0288829              N/A     12.56m\n",
            "   6     8.97        0.0189026        9        0.0279423              N/A      9.47m\n",
            "   7     8.90        0.0189426        9        0.0279423              N/A      6.22m\n",
            "   8     9.07        0.0193499        9        0.0279423              N/A      3.11m\n",
            "   9     9.05        0.0190054        9        0.0279423              N/A      0.00s\n",
            "you successfully evolved new atomic programs\n",
            "look at the models you evolved\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc888431990>, 'program_str': 'sub(mul(feature_strength14, feature_charisma43), sub(feature_dexterity12, sub(feature_charisma76, feature_dexterity6)))', 'corr': 0.010661639884810033}\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc88f7feed0>, 'program_str': 'sub(mul(feature_strength14, feature_charisma43), sub(feature_dexterity12, sub(feature_charisma76, feature_dexterity6)))', 'corr': 0.010661639884810033}\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc88e19c590>, 'program_str': 'sub(feature_dexterity12, sub(feature_charisma76, sub(feature_dexterity6, mul(feature_charisma43, feature_strength14))))', 'corr': -0.010814797535735221}\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc88d0aa4d0>, 'program_str': 'sub(mul(feature_charisma43, feature_strength14), sub(feature_dexterity12, sub(feature_charisma76, feature_dexterity6)))', 'corr': 0.010661639884810033}\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc88f7fdb50>, 'program_str': 'sub(mul(feature_strength14, feature_charisma43), sub(feature_dexterity12, sub(feature_charisma76, feature_dexterity6)))', 'corr': 0.010661639884810033}\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc88d0aa410>, 'program_str': 'sub(mul(feature_charisma43, feature_strength14), sub(feature_dexterity12, sub(feature_charisma76, feature_dexterity6)))', 'corr': 0.010661639884810033}\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc88a022750>, 'program_str': 'sub(feature_dexterity12, sub(feature_charisma76, sub(feature_dexterity6, mul(feature_charisma43, feature_strength14))))', 'corr': -0.010814797535735221}\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc88e19c5d0>, 'program_str': 'sub(feature_dexterity12, sub(feature_charisma76, sub(feature_dexterity6, mul(feature_strength14, feature_charisma43))))', 'corr': -0.010814797535735221}\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc88c621a50>, 'program_str': 'sub(mul(feature_charisma43, feature_strength14), sub(feature_dexterity12, sub(feature_charisma76, feature_dexterity6)))', 'corr': 0.010661639884810033}\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc88f7ce310>, 'program_str': 'sub(mul(feature_strength14, feature_charisma43), sub(feature_dexterity12, sub(feature_charisma76, feature_dexterity6)))', 'corr': 0.010661639884810033}\n",
            "after one run  have this many atomic programs\n",
            "20\n",
            "BATCH 1\n",
            "now EVOLVING\n",
            "    |   Population Average    |             Best Individual              |\n",
            "---- ------------------------- ------------------------------------------ ----------\n",
            " Gen   Length          Fitness   Length          Fitness      OOB Fitness  Time Left\n",
            "   0    16.35       0.00353863       10        0.0196834              N/A     34.57m\n",
            "   1     3.07        0.0123163       10        0.0228218              N/A     23.98m\n",
            "   2     3.73        0.0179234       10        0.0250376              N/A     21.76m\n",
            "   3     6.47         0.019212       15        0.0281007              N/A     20.66m\n",
            "   4     8.17        0.0209184       17        0.0295452              N/A     17.07m\n",
            "   5    10.58        0.0224915       19        0.0323185              N/A     14.02m\n",
            "   6    12.94        0.0240923       24        0.0305447              N/A     11.18m\n",
            "   7    13.35        0.0247739       14        0.0303961              N/A      7.91m\n",
            "   8    12.90        0.0249856       13        0.0302696              N/A      3.81m\n",
            "   9    13.00        0.0248438       13        0.0302696              N/A      0.00s\n",
            "you successfully evolved new atomic programs\n",
            "look at the models you evolved\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc88a2b1610>, 'program_str': 'sub(feature_charisma69, sub(add(mul(feature_charisma11, feature_strength1), add(feature_strength34, sub(feature_charisma76, feature_dexterity4))), feature_dexterity6))', 'corr': -0.011898148037870168}\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc8999d4690>, 'program_str': 'sub(feature_charisma69, sub(add(feature_strength34, add(mul(feature_charisma11, feature_strength1), sub(feature_charisma76, feature_dexterity4))), feature_dexterity6))', 'corr': -0.011898148037870168}\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc888431550>, 'program_str': 'sub(feature_charisma69, sub(add(mul(feature_charisma11, feature_strength1), add(feature_strength34, sub(feature_charisma76, feature_dexterity4))), feature_dexterity6))', 'corr': -0.011898148037870168}\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc8999d4b50>, 'program_str': 'sub(feature_charisma69, sub(add(mul(feature_charisma11, feature_strength1), add(feature_strength34, sub(feature_charisma76, feature_dexterity4))), feature_dexterity6))', 'corr': -0.011898148037870168}\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc888431590>, 'program_str': 'sub(feature_charisma69, sub(add(mul(feature_charisma11, feature_strength1), add(feature_strength34, sub(feature_charisma76, feature_dexterity4))), feature_dexterity6))', 'corr': -0.011898148037870168}\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc8999d4e50>, 'program_str': 'sub(feature_charisma69, sub(add(mul(feature_charisma11, feature_strength1), add(feature_strength34, sub(feature_charisma76, feature_dexterity4))), feature_dexterity6))', 'corr': -0.011898148037870168}\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc88fb9bd90>, 'program_str': 'sub(feature_charisma69, sub(add(mul(feature_charisma11, feature_strength1), add(feature_strength34, sub(feature_charisma76, feature_dexterity4))), feature_dexterity6))', 'corr': -0.011898148037870168}\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc8a5e9b1d0>, 'program_str': 'sub(feature_charisma69, sub(add(mul(feature_charisma11, feature_strength1), add(feature_strength34, sub(feature_charisma76, feature_dexterity4))), feature_dexterity6))', 'corr': -0.011898148037870168}\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc8a3a0f190>, 'program_str': 'sub(feature_charisma69, sub(add(mul(feature_charisma11, feature_strength1), add(feature_strength34, sub(feature_charisma76, feature_dexterity4))), feature_dexterity6))', 'corr': -0.011898148037870168}\n",
            "{'program_obj': <gplearn._program._Program object at 0x7fc88757a450>, 'program_str': 'sub(feature_charisma69, sub(add(mul(feature_charisma11, feature_strength1), add(feature_strength34, sub(feature_charisma76, feature_dexterity4))), feature_dexterity6))', 'corr': -0.011898148037870168}\n",
            "after one run  have this many atomic programs\n",
            "20\n",
            "CPU times: user 4min 33s, sys: 48.6 s, total: 5min 22s\n",
            "Wall time: 1h 8min 40s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcuZRZyqitYi",
        "outputId": "7ff56925-d3a8-470c-ccfc-dfd338c3745c"
      },
      "source": [
        "  log_pickle_location = \"/content/log_0.pkl\" # change this on your desktop.\n",
        "\n",
        "  #Read already evolved atomic programs from disk.\n",
        "  atomic_programs_file = open(log_pickle_location,'rb')\n",
        "  list_of_atomic_programs = pickle.load(atomic_programs_file)\n",
        "  atomic_programs_file.close()\n",
        "  list_of_atomic_programs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'corr': 0.011806513304690652,\n",
              "  'program_obj': <gplearn._program._Program at 0x7fc8a2de58d0>,\n",
              "  'program_str': 'sub(feature_charisma81, add(feature_dexterity4, feature_charisma9))'},\n",
              " {'corr': 0.011374751191345962,\n",
              "  'program_obj': <gplearn._program._Program at 0x7fc8a4475890>,\n",
              "  'program_str': 'div(divide_by_two(feature_charisma19), feature_dexterity7)'},\n",
              " {'corr': 0.0032107744621358704,\n",
              "  'program_obj': <gplearn._program._Program at 0x7fc8a4475c10>,\n",
              "  'program_str': 'div(divide_by_two(sub(feature_charisma81, feature_dexterity5)), feature_dexterity7)'},\n",
              " {'corr': 0.002592926093802197,\n",
              "  'program_obj': <gplearn._program._Program at 0x7fc8a4477e50>,\n",
              "  'program_str': 'div(sub(feature_charisma81, feature_dexterity5), feature_dexterity7)'},\n",
              " {'corr': -0.010206892131194327,\n",
              "  'program_obj': <gplearn._program._Program at 0x7fc8a4477b50>,\n",
              "  'program_str': 'add(feature_dexterity4, feature_charisma9)'},\n",
              " {'corr': 0.006996421414364752,\n",
              "  'program_obj': <gplearn._program._Program at 0x7fc8a2d2b2d0>,\n",
              "  'program_str': 'div(feature_charisma81, feature_dexterity7)'},\n",
              " {'corr': 0.001605656274289496,\n",
              "  'program_obj': <gplearn._program._Program at 0x7fc8a2d2bf50>,\n",
              "  'program_str': 'div(sub(feature_charisma40, feature_dexterity5), feature_dexterity7)'},\n",
              " {'corr': 0.0020800474491575426,\n",
              "  'program_obj': <gplearn._program._Program at 0x7fc8a23eca50>,\n",
              "  'program_str': 'div(divide_by_two(sub(feature_charisma40, feature_dexterity5)), feature_dexterity7)'},\n",
              " {'corr': 0.0071804894369322,\n",
              "  'program_obj': <gplearn._program._Program at 0x7fc89c16a5d0>,\n",
              "  'program_str': 'neg(sub(feature_dexterity11, div(feature_charisma55, feature_dexterity7)))'},\n",
              " {'corr': 0.002104134370293714,\n",
              "  'program_obj': <gplearn._program._Program at 0x7fc89ccb2d10>,\n",
              "  'program_str': 'sub(feature_charisma81, feature_dexterity5)'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu6-tVJsnBRi"
      },
      "source": [
        "### See the evaluations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl2xBUa2iuZA"
      },
      "source": [
        "tournament_df = pd.read_csv(f'/content/numerai_dataset_{275}/numerai_tournament_data.csv', index_col=0) # already loaded you can comment out.\n",
        "feature_cols = [c for c in tournament_df.columns if c.startswith(\"feature\")]\n",
        "valid_df = tournament_df[tournament_df[\"data_type\"] == \"validation\"].reset_index(drop = True)\n",
        "valid_X = valid_df[feature_cols]\n",
        "valid_y = valid_df['target']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K36uch2DjBtO",
        "outputId": "1f0ddfb1-117b-4da9-9a8a-98000a6394f8"
      },
      "source": [
        "prediction_df = pd.DataFrame(index=valid_X.index)\n",
        "for index, prog in enumerate(list_of_atomic_programs):\n",
        "  transformation_name =f\"transformation_{index}\"\n",
        "  prediction_df[transformation_name] = prog['program_obj'].execute(valid_X.values)\n",
        "\n",
        "res = pd.DataFrame()\n",
        "res['prediction'] = prediction_df.mean(axis=1)\n",
        "res['target'] = valid_y.values # \n",
        "print('CORR on Unseen Validation data')\n",
        "print(score(res))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CORR on Unseen Validation data\n",
            "0.006281574187073034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "odU7hgVHmnoH",
        "outputId": "01487f9e-6240-4c57-cf66-595aa5b89530"
      },
      "source": [
        "prediction_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>transformation_0</th>\n",
              "      <th>transformation_1</th>\n",
              "      <th>transformation_2</th>\n",
              "      <th>transformation_3</th>\n",
              "      <th>transformation_4</th>\n",
              "      <th>transformation_5</th>\n",
              "      <th>transformation_6</th>\n",
              "      <th>transformation_7</th>\n",
              "      <th>transformation_8</th>\n",
              "      <th>transformation_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.25</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.666667</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-2.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>-0.750000</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.750000</td>\n",
              "      <td>-0.375000</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>-0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>-0.333333</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>-0.000000</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.25</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>-0.750000</td>\n",
              "      <td>-0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137774</th>\n",
              "      <td>0.25</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.50</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137775</th>\n",
              "      <td>0.00</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137776</th>\n",
              "      <td>-0.25</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137777</th>\n",
              "      <td>-0.75</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.250000</td>\n",
              "      <td>-0.500000</td>\n",
              "      <td>-0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137778</th>\n",
              "      <td>-0.75</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-2.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>-0.50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>137779 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        transformation_0  transformation_1  ...  transformation_8  transformation_9\n",
              "0                  -1.25          0.166667  ...         -0.000000             -0.50\n",
              "1                  -2.00          0.000000  ...         -0.000000             -0.75\n",
              "2                  -0.25          0.666667  ...          1.333333              0.25\n",
              "3                   0.00          0.333333  ...         -0.000000              0.00\n",
              "4                  -0.25          1.000000  ...         -0.750000             -0.25\n",
              "...                  ...               ...  ...               ...               ...\n",
              "137774              0.25          2.000000  ...          3.250000              0.00\n",
              "137775              0.00          1.500000  ...          3.500000              0.50\n",
              "137776             -0.25          0.000000  ...          0.833333              0.50\n",
              "137777             -0.75          0.750000  ...         -0.500000             -0.50\n",
              "137778             -0.75          0.500000  ...          1.250000             -0.50\n",
              "\n",
              "[137779 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByQD5XiSvgX3"
      },
      "source": [
        ""
      ]
    }
  ]
}