{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7atJJ2fMiJ8"
      },
      "source": [
        "# Experimentation with different loss function and Evaluation metrics. \r\n",
        "\r\n",
        "\r\n",
        "Create a sub evaluation method to count the % of eras that you have >0 corr for. \r\n",
        "\r\n",
        "You might want  explor hyper parm for xgboost as well. and some other out of the box algos\r\n",
        "\r\n",
        "You might want a custom loss function of \"brair score\"  sum(true_outcome - prediction)^2 for all outcome, preiction in df. \r\n",
        "\r\n",
        "Put this in the validation scorring methods. add it to score summary\r\n",
        "\r\n",
        "You can do rank corrilation at each iteration.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "X4WFeO-ZMiKC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import os, sys\r\n",
        "import gc\r\n",
        "import pathlib\r\n",
        "import json\r\n",
        "import datetime\r\n",
        "from typing import List, NoReturn, Union, Tuple, Optional, Text, Generic, Callable, Dict\r\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, QuantileTransformer\r\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, TimeSeriesSplit\r\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, mean_squared_error, mean_absolute_error, f1_score\r\n",
        "from scipy.stats import spearmanr # -P I think this is corr. \r\n",
        "import joblib\r\n",
        "import numerapi\r\n",
        "# model\r\n",
        "import lightgbm as lgb\r\n",
        "\r\n",
        "import operator\r\n",
        "\r\n",
        "# visualize\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.style as style\r\n",
        "from matplotlib import pyplot\r\n",
        "from matplotlib.ticker import ScalarFormatter\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y0ELMvF79l3D"
      },
      "outputs": [],
      "source": [
        "on_colab = False\r\n",
        "if on_colab:\r\n",
        "    !pip install numerapi\r\n",
        "    from google.colab import drive\r\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b364c12-MiKD"
      },
      "source": [
        "## Methods to Gather and Clean Incoming Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmV-K6xHoqxW"
      },
      "outputs": [],
      "source": [
        "def create_global_variables()-> None:\r\n",
        "  \"\"\"\r\n",
        "    Create all global variables. \r\n",
        "    ROUND_NUMBER,FEATURES,TARGET,\r\n",
        "    TOURNAMENT_DATA,TRAINING_DATA,VALIDATION_DATA\r\n",
        "  \"\"\"\r\n",
        "  try:\r\n",
        "    if HAVE_GATHERED_DATA == FALSE:\r\n",
        "      print('getting training_data')\r\n",
        "      ping_training_data()\r\n",
        "      print('getting tournament data')\r\n",
        "      ping_tournament_data()\r\n",
        "      create_validation_data(df = TOURNAMENT_DATA)\r\n",
        "      print('created valid df')\r\n",
        "      create_global_constants()\r\n",
        "      drop_data_type_columns()\r\n",
        "      HAVE_GATHERED_DATA = True\r\n",
        "      print('finished gathering data')\r\n",
        "  except NameError:\r\n",
        "      print('getting training_data')\r\n",
        "      ping_training_data()\r\n",
        "      print('getting tournament data')\r\n",
        "      ping_tournament_data()\r\n",
        "      create_validation_data(df = TOURNAMENT_DATA)\r\n",
        "      print('created valid df')\r\n",
        "      create_global_constants()\r\n",
        "      drop_data_type_columns()\r\n",
        "      HAVE_GATHERED_DATA = True\r\n",
        "      print('finished gathering data')\r\n",
        "\r\n",
        "def drop_data_type_columns():\r\n",
        "  TRAINING_DATA.drop(columns=[\"data_type\"], inplace=True)\r\n",
        "  VALIDATION_DATA.drop(columns=[\"data_type\"], inplace=True) #\r\n",
        "  TOURNAMENT_DATA.drop(columns=[\"data_type\"], inplace=True)\r\n",
        "\r\n",
        "def ping_training_data():\r\n",
        "  global TRAINING_DATA\r\n",
        "  TRAINING_DATA = read_data('train')\r\n",
        "  \r\n",
        "def ping_tournament_data():\r\n",
        "  global TOURNAMENT_DATA\r\n",
        "  TOURNAMENT_DATA = read_data('tournament')\r\n",
        "\r\n",
        "def create_validation_data(df):\r\n",
        "  global VALIDATION_DATA\r\n",
        "  VALIDATION_DATA  = df[df[\"data_type\"] == \"validation\"].reset_index(drop = True)\r\n",
        "\r\n",
        "def cast_eras_as_int(x): \r\n",
        "    try:\r\n",
        "        return int(x[3:]) # strip the first 3 characters from each era\r\n",
        "    except:\r\n",
        "        return -99\r\n",
        "\r\n",
        "def read_data(data):\r\n",
        "    if data == 'train':\r\n",
        "        df = pd.read_csv('https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_training_data.csv.xz')\r\n",
        "    elif data == 'tournament':\r\n",
        "        df = pd.read_csv('https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_tournament_data.csv.xz')\r\n",
        "        \r\n",
        "    feature_cols = df.columns[df.columns.str.startswith('feature')]\r\n",
        "    mapping = {0.0 : 0, 0.25 : 1, 0.5 : 2, 0.75 : 3, 1.0 : 4}\r\n",
        "\r\n",
        "    for c in feature_cols:\r\n",
        "        df[c] = df[c].map(mapping).astype(np.uint8)\r\n",
        "        \r\n",
        "    df[\"era\"] = df[\"era\"].apply(cast_eras_as_int)\r\n",
        "    return df\r\n",
        "\r\n",
        "\r\n",
        "def create_global_constants() -> None:\r\n",
        "  global TARGET\r\n",
        "  TARGET = get_target_constant(TOURNAMENT_DATA)\r\n",
        "  global FEATURES\r\n",
        "  FEATURES = get_features_constant(TOURNAMENT_DATA)\r\n",
        "  napi = open_api_access()\r\n",
        "  global ROUND_NUMBER\r\n",
        "  ROUND_NUMBER = napi.get_current_round()\r\n",
        "\r\n",
        "\r\n",
        "def get_target_constant(tournament_data: pd.DataFrame):\r\n",
        "  return tournament_data.columns[tournament_data.columns.str.startswith('target')].values.tolist()[0]\r\n",
        "\r\n",
        "\r\n",
        "def get_features_constant(tournament_data: pd.DataFrame):\r\n",
        "  return [column_names for column_names in tournament_data.columns.values.tolist() if 'feature' in column_names]\r\n",
        "\r\n",
        "\r\n",
        "def load_api_creds_into_dict():\r\n",
        "  if on_colab:\r\n",
        "    creds = open('/content/drive/MyDrive/creds.json','r')\r\n",
        "  else:\r\n",
        "    creds = open('creds.json', 'r') \r\n",
        "  api_keys_dict = json.load(creds)\r\n",
        "  creds.close()\r\n",
        "  return api_keys_dict\r\n",
        "\r\n",
        "\r\n",
        "def open_api_access():\r\n",
        "  api_keys_dict = load_api_creds_into_dict()\r\n",
        "  my_secret_key = api_keys_dict['secret_key']\r\n",
        "  my_public_id = api_keys_dict['public_id']\r\n",
        "  napi = numerapi.NumerAPI(secret_key=my_secret_key, public_id=my_public_id)\r\n",
        "  return napi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBuYhojHFcQW"
      },
      "source": [
        "# Get the training and testing data and create the global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M3eMSLtXzspp",
        "outputId": "b8d8ce6c-bd92-4c27-a599-5bcc6d1b1a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "getting training_data\n",
            "getting tournament data\n",
            "created valid df\n",
            "finished gathering data\n"
          ]
        }
      ],
      "source": [
        "create_global_variables() # works with python 64 bit conda\r\n",
        "HAVE_GATHERED_DATA = True "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 id  era  feature_intelligence1  feature_intelligence2  \\\n",
            "0  n000315175b67977    1                      0                      2   \n",
            "1  n0014af834a96cdd    1                      0                      0   \n",
            "2  n001c93979ac41d4    1                      1                      2   \n",
            "3  n0034e4143f22a13    1                      4                      0   \n",
            "4  n00679d1a636062f    1                      1                      1   \n",
            "\n",
            "   feature_intelligence3  feature_intelligence4  feature_intelligence5  \\\n",
            "0                      1                      0                      2   \n",
            "1                      0                      1                      2   \n",
            "2                      1                      1                      4   \n",
            "3                      0                      2                      2   \n",
            "4                      1                      1                      0   \n",
            "\n",
            "   feature_intelligence6  feature_intelligence7  feature_intelligence8  ...  \\\n",
            "0                      1                      1                      1  ...   \n",
            "1                      0                      0                      1  ...   \n",
            "2                      3                      3                      1  ...   \n",
            "3                      1                      1                      3  ...   \n",
            "4                      1                      2                      1  ...   \n",
            "\n",
            "   feature_wisdom38  feature_wisdom39  feature_wisdom40  feature_wisdom41  \\\n",
            "0                 4                 4                 3                 2   \n",
            "1                 4                 4                 0                 0   \n",
            "2                 1                 2                 0                 0   \n",
            "3                 4                 4                 3                 3   \n",
            "4                 3                 3                 1                 2   \n",
            "\n",
            "   feature_wisdom42  feature_wisdom43  feature_wisdom44  feature_wisdom45  \\\n",
            "0                 3                 2                 4                 2   \n",
            "1                 3                 1                 0                 1   \n",
            "2                 2                 4                 0                 1   \n",
            "3                 4                 4                 3                 4   \n",
            "4                 3                 0                 2                 1   \n",
            "\n",
            "   feature_wisdom46  target  \n",
            "0                 3    0.50  \n",
            "1                 4    0.25  \n",
            "2                 3    0.25  \n",
            "3                 4    0.25  \n",
            "4                 3    0.75  \n",
            "\n",
            "[5 rows x 313 columns]\n",
            "                 id  era  feature_intelligence1  feature_intelligence2  \\\n",
            "0  n0003aa52cab36c2  121                      1                      3   \n",
            "1  n000920ed083903f  121                      3                      2   \n",
            "2  n0038e640522c4a6  121                      4                      0   \n",
            "3  n004ac94a87dc54b  121                      3                      4   \n",
            "4  n0052fe97ea0c05f  121                      1                      2   \n",
            "\n",
            "   feature_intelligence3  feature_intelligence4  feature_intelligence5  \\\n",
            "0                      2                      2                      0   \n",
            "1                      3                      4                      2   \n",
            "2                      0                      4                      4   \n",
            "3                      4                      2                      0   \n",
            "4                      2                      1                      4   \n",
            "\n",
            "   feature_intelligence6  feature_intelligence7  feature_intelligence8  ...  \\\n",
            "0                      3                      2                      1  ...   \n",
            "1                      0                      0                      3  ...   \n",
            "2                      4                      4                      4  ...   \n",
            "3                      0                      0                      2  ...   \n",
            "4                      2                      2                      1  ...   \n",
            "\n",
            "   feature_wisdom38  feature_wisdom39  feature_wisdom40  feature_wisdom41  \\\n",
            "0                 3                 3                 4                 3   \n",
            "1                 2                 2                 3                 4   \n",
            "2                 0                 0                 2                 1   \n",
            "3                 0                 0                 0                 1   \n",
            "4                 2                 3                 0                 0   \n",
            "\n",
            "   feature_wisdom42  feature_wisdom43  feature_wisdom44  feature_wisdom45  \\\n",
            "0                 2                 2                 4                 0   \n",
            "1                 3                 2                 2                 2   \n",
            "2                 0                 0                 2                 2   \n",
            "3                 0                 0                 0                 1   \n",
            "4                 3                 4                 0                 1   \n",
            "\n",
            "   feature_wisdom46  target  \n",
            "0                 0    0.25  \n",
            "1                 2    0.50  \n",
            "2                 0    1.00  \n",
            "3                 1    0.50  \n",
            "4                 4    0.75  \n",
            "\n",
            "[5 rows x 313 columns]\n",
            "                 id  era  feature_intelligence1  feature_intelligence2  \\\n",
            "0  n0003aa52cab36c2  121                      1                      3   \n",
            "1  n000920ed083903f  121                      3                      2   \n",
            "2  n0038e640522c4a6  121                      4                      0   \n",
            "3  n004ac94a87dc54b  121                      3                      4   \n",
            "4  n0052fe97ea0c05f  121                      1                      2   \n",
            "\n",
            "   feature_intelligence3  feature_intelligence4  feature_intelligence5  \\\n",
            "0                      2                      2                      0   \n",
            "1                      3                      4                      2   \n",
            "2                      0                      4                      4   \n",
            "3                      4                      2                      0   \n",
            "4                      2                      1                      4   \n",
            "\n",
            "   feature_intelligence6  feature_intelligence7  feature_intelligence8  ...  \\\n",
            "0                      3                      2                      1  ...   \n",
            "1                      0                      0                      3  ...   \n",
            "2                      4                      4                      4  ...   \n",
            "3                      0                      0                      2  ...   \n",
            "4                      2                      2                      1  ...   \n",
            "\n",
            "   feature_wisdom38  feature_wisdom39  feature_wisdom40  feature_wisdom41  \\\n",
            "0                 3                 3                 4                 3   \n",
            "1                 2                 2                 3                 4   \n",
            "2                 0                 0                 2                 1   \n",
            "3                 0                 0                 0                 1   \n",
            "4                 2                 3                 0                 0   \n",
            "\n",
            "   feature_wisdom42  feature_wisdom43  feature_wisdom44  feature_wisdom45  \\\n",
            "0                 2                 2                 4                 0   \n",
            "1                 3                 2                 2                 2   \n",
            "2                 0                 0                 2                 2   \n",
            "3                 0                 0                 0                 1   \n",
            "4                 3                 4                 0                 1   \n",
            "\n",
            "   feature_wisdom46  target  \n",
            "0                 0    0.25  \n",
            "1                 2    0.50  \n",
            "2                 0    1.00  \n",
            "3                 1    0.50  \n",
            "4                 4    0.75  \n",
            "\n",
            "[5 rows x 313 columns]\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4khTMbONzW-"
      },
      "source": [
        "### ModelStats Object\n",
        "\n",
        "1. Stores the Trained Model\n",
        "2. Stores the Hyper Parameters\n",
        "3. Stores the Validation Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6LCuE_km4Y_3"
      },
      "outputs": [],
      "source": [
        "if on_colab:\r\n",
        "  PATH_TO_SAVE_SCORES = '/content/drive/MyDrive/numerai_hyperparams_scores.csv'\r\n",
        "else:\r\n",
        "  PATH_TO_SAVE_SCORES = ''\r\n",
        "\r\n",
        "class ModelStats():\r\n",
        "  \"\"\"\r\n",
        "  An object that tracks Hyper Parameters, Time Costs and Scores. \r\n",
        "  \"\"\"\r\n",
        "  def __init__(self, model, scores:dict, total_time):\r\n",
        "        self.model = model \r\n",
        "        self.hyperparams = model.get_params() \r\n",
        "        self.scores = scores \r\n",
        "        self.total_time = total_time\r\n",
        "        self.params_scores_df = None \r\n",
        "\r\n",
        "\r\n",
        "  def create_params_scores_df(self):\r\n",
        "    \"\"\"\r\n",
        "    Create a DataFrame Representing the Hyper Parameters and Scores of this model.\r\n",
        "    \"\"\"\r\n",
        "    if self.params_scores_df == None:\r\n",
        "      all_stats_dict = {}\r\n",
        "      all_stats_dict['total_time'] = self.total_time\r\n",
        "      all_stats_dict['round_number'] = ROUND_NUMBER\r\n",
        "      all_stats_dict.update(self.hyperparams) # dict.update(dict) merges two dictionaries\r\n",
        "      all_stats_dict.update(self.scores)\r\n",
        "      DECIMALS = 4 \r\n",
        "      for key in all_stats_dict.keys():\r\n",
        "          try:\r\n",
        "            all_stats_dict[key] = [round(all_stats_dict[key],DECIMALS)]\r\n",
        "          except:\r\n",
        "            all_stats_dict[key] = [all_stats_dict[key]]\r\n",
        "\r\n",
        "      self.params_scores_df = pd.DataFrame.from_dict(all_stats_dict)\r\n",
        "\r\n",
        "  \r\n",
        "  def save_hyperparams_scores_to_google_drive_tabular(self)-> None:\r\n",
        "    \"\"\"\r\n",
        "        Appends this model's scores into your Google Drive with the other scores.\r\n",
        "    \"\"\"\r\n",
        "    self.create_params_scores_df()\r\n",
        "    # try to load that current df into memory\r\n",
        "    disk_df = pd.read_csv(PATH_TO_SAVE_SCORES)\r\n",
        "    #print(f'Read in new saved scores with {disk_df.shape} shape')\r\n",
        "    new_updated_disk_df = merge_dfs_horizontally(disk_df, self.params_scores_df)\r\n",
        "    #print(f'added next line of scores with {new_updated_disk_df.shape} shape')\r\n",
        "    new_updated_disk_df.to_csv(PATH_TO_SAVE_SCORES, index=False)\r\n",
        "    #print('Overwrote the new_updated_disk_df to your Google Drive')\r\n",
        "\r\n",
        "    try:\r\n",
        "      with open(PATH_TO_SAVE_SCORES, 'r') as scores_file:\r\n",
        "          lines = scores_file.readlines()\r\n",
        "          if len(lines) == 0:\r\n",
        "            print(\"the file does not exist. You are good to save your first score df\")\r\n",
        "    except:\r\n",
        "      self.params_scores_df.to_csv(PATH_TO_SAVE_SCORES, index=False)\r\n",
        "      # not exhaustively tested   \r\n",
        "           \r\n",
        "\r\n",
        "def merge_dfs_horizontally(df1 : pd.DataFrame, df2: pd.DataFrame)-> pd.DataFrame:\r\n",
        "  merged_df = pd.concat([df1, df2], axis=0)\r\n",
        "  return merged_df\r\n",
        "\r\n",
        "\r\n",
        "def train_LGBMRegressor(params: dict, train_data): \r\n",
        "  \"\"\"\r\n",
        "  Inputs: a dict of hyper paramaters for the model, \r\n",
        "  train_data: a pd.DataFrame of the Training Data\r\n",
        "\r\n",
        "  Returns a trained model\r\n",
        "  \"\"\"\r\n",
        "  model = lgb.LGBMRegressor(**params) \r\n",
        "  model.fit(train_data[FEATURES], train_data[TARGET])\r\n",
        "  return model\r\n",
        "\r\n",
        "def train_xgboost(train_data): \r\n",
        "  \"\"\"\r\n",
        "    Not deeply tested. Has much higher 10x time costs to train a single modle. \r\n",
        "    with these params it is low end but respectable. but takes about 2 hours to train via google colab\r\n",
        "  \"\"\"\r\n",
        "  model = xgb.XGBRegressor(max_depth=5, learning_rate=0.01, n_estimators=2000, n_jobs=-1, colsample_bytree=0.1)\r\n",
        "  model.fit(train_data[FEATURES], train_data[TARGET])\r\n",
        "  return model\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bWSBkk2_m3h"
      },
      "source": [
        "#### Methods to Determine Validation Scores\n",
        "\n",
        "1. I did not write these. I added the English comments\n",
        "source https://www.kaggle.com/code1110/numerai-tournament"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "szXbJM0mMiKJ"
      },
      "outputs": [],
      "source": [
        "# naming conventions\n",
        "PREDICTION_NAME = 'prediction'\n",
        "TARGET_NAME = TARGET # 'target is the string named 'target'\n",
        "# EXAMPLE_PRED = 'example_prediction'\n",
        "\n",
        "# ---------------------------\n",
        "# Functions\n",
        "# ---------------------------\n",
        "def valid4score(valid : pd.DataFrame, pred : np.ndarray, load_example: bool=True, save : bool=False) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generate new valid pandas dataframe for computing scores\n",
        "    \n",
        "    :INPUT:\n",
        "    - valid : pd.DataFrame extracted from tournament data (data_type='validation')\n",
        "    \n",
        "    \"\"\"\n",
        "    valid_df = valid.copy() # the validation dataframe you use this to test the CORR and other values\n",
        "\n",
        "    # Your model creates an array of floats [0,1] rank method converst them in a list of ints. \n",
        "\n",
        "    # your lis tof ints is then compared to their list of ints. \n",
        "    valid_df['prediction'] = pd.Series(pred).rank(pct=True, method=\"first\") # pred is the array of predictions your model creates for the set of validation vectors.  \n",
        "    # I am unsure if this preds is a float only only between 0,1,2,3,4. \n",
        "    valid_df.rename(columns={TARGET: 'target'}, inplace=True)\n",
        "    \n",
        "    # I don't know what the load example boolean is. I think you can use this to save predictions.\n",
        "    if load_example:\n",
        "        valid_df[EXAMPLE_PRED] = pd.read_csv(EXP_DIR + 'valid_df.csv')['prediction'].values\n",
        "    \n",
        "    if save==True:\n",
        "        valid_df.to_csv(OUTPUT_DIR + 'valid_df.csv', index=False)\n",
        "        print('Validation dataframe saved!')\n",
        "    \n",
        "    return valid_df\n",
        "\n",
        "def compute_corr(valid_df : pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Compute rank correlation\n",
        "\n",
        "    THIS IS WHAT YOU ARE PRIMARILY PAID ON \n",
        "    \n",
        "    :INPUT:\n",
        "    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n",
        "    \n",
        "    \"\"\"\n",
        "    # this uses Person Correilation. \n",
        "    # I You are paid on spearman corrilation. That is where the ratio of change is important not the raw amount of change\n",
        "    # see: https://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/supporting-topics/basics/a-comparison-of-the-pearson-and-spearman-correlation-methods/\n",
        "    return np.corrcoef(valid_df[\"target\"], valid_df['prediction'])[0, 1]\n",
        "\n",
        "def compute_max_drawdown(validation_correlations : pd.Series):\n",
        "    \"\"\"\n",
        "    Compute max drawdown\n",
        "    \n",
        "    :INPUT:\n",
        "    - validation_correaltions : pd.Series\n",
        "    \"\"\"\n",
        "    \n",
        "    rolling_max = (validation_correlations + 1).cumprod().rolling(window=100, min_periods=1).max()\n",
        "    daily_value = (validation_correlations + 1).cumprod()\n",
        "    max_drawdown = -(rolling_max - daily_value).max()\n",
        "    \n",
        "    return max_drawdown\n",
        "\n",
        "def compute_val_corr(valid_df : pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Compute rank correlation for valid periods\n",
        "    \n",
        "    :INPUT:\n",
        "    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n",
        "    \"\"\"\n",
        "    \n",
        "    # all validation\n",
        "    correlation = compute_corr(valid_df)\n",
        "    #print(\"rank corr = {:.4f}\".format(correlation))\n",
        "    return correlation\n",
        "    \n",
        "def compute_val_sharpe(valid_df : pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Compute sharpe ratio for valid periods\n",
        "    \n",
        "    :INPUT:\n",
        "    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n",
        "    \"\"\"\n",
        "    # all validation\n",
        "    d = valid_df.groupby('era')[['target', 'prediction']].corr().iloc[0::2,-1].reset_index()\n",
        "    me = d['prediction'].mean()\n",
        "    sd = d['prediction'].std()\n",
        "    max_drawdown = compute_max_drawdown(d['prediction'])\n",
        "    #print('sharpe ratio = {:.4f}, corr mean = {:.4f}, corr std = {:.4f}, max drawdown = {:.4f}'.format(me / sd, me, sd, max_drawdown))\n",
        "    \n",
        "    return me / sd, me, sd, max_drawdown\n",
        "    \n",
        "def feature_exposures(valid_df : pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Compute feature exposure\n",
        "    \n",
        "    :INPUT:\n",
        "    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n",
        "    \"\"\"\n",
        "    feature_names = [f for f in valid_df.columns\n",
        "                     if f.startswith(\"feature\")]\n",
        "    exposures = []\n",
        "    for f in feature_names:\n",
        "        fe = spearmanr(valid_df['prediction'], valid_df[f])[0]\n",
        "        exposures.append(fe)\n",
        "    return np.array(exposures)\n",
        "\n",
        "def max_feature_exposure(fe : np.ndarray):\n",
        "    return np.max(np.abs(fe))\n",
        "\n",
        "def feature_exposure(fe : np.ndarray):\n",
        "    return np.sqrt(np.mean(np.square(fe)))\n",
        "\n",
        "def compute_val_feature_exposure(valid_df : pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Compute feature exposure for valid periods\n",
        "    \n",
        "    :INPUT:\n",
        "    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n",
        "    \"\"\"\n",
        "    # all validation\n",
        "    fe = feature_exposures(valid_df)\n",
        "    fe1, fe2 = feature_exposure(fe), max_feature_exposure(fe)\n",
        "    #print('feature exposure = {:.4f}, max feature exposure = {:.4f}'.format(fe1, fe2))\n",
        "     \n",
        "    return fe1, fe2\n",
        "\n",
        "# to neutralize a column in a df by many other columns\n",
        "#         I have no idea what this method does. -P. need to read about it and write up a link to it. \n",
        "def neutralize(df, columns, by, proportion=1.0):\n",
        "    scores = df.loc[:, columns]\n",
        "    exposures = df[by].values\n",
        "\n",
        "    # constant column to make sure the series is completely neutral to exposures\n",
        "    exposures = np.hstack(\n",
        "        (exposures,\n",
        "         np.asarray(np.mean(scores)) * np.ones(len(exposures)).reshape(-1, 1)))\n",
        "\n",
        "    scores = scores - proportion * exposures.dot(\n",
        "        np.linalg.pinv(exposures).dot(scores))\n",
        "    return scores / scores.std()\n",
        "\n",
        "\n",
        "# to neutralize any series by any other series\n",
        "def neutralize_series(series, by, proportion=1.0):\n",
        "    scores = series.values.reshape(-1, 1)\n",
        "    exposures = by.values.reshape(-1, 1)\n",
        "\n",
        "    # this line makes series neutral to a constant column so that it's centered and for sure gets corr 0 with exposures\n",
        "    exposures = np.hstack(\n",
        "        (exposures,\n",
        "         np.array([np.mean(series)] * len(exposures)).reshape(-1, 1)))\n",
        "\n",
        "    correction = proportion * (exposures.dot(\n",
        "        np.linalg.lstsq(exposures, scores, rcond=None)[0]))\n",
        "    corrected_scores = scores - correction\n",
        "    neutralized = pd.Series(corrected_scores.ravel(), index=series.index)\n",
        "    return neutralized\n",
        "\n",
        "\n",
        "def unif(df):\n",
        "    x = (df.rank(method=\"first\") - 0.5) / len(df)\n",
        "    return pd.Series(x, index=df.index)\n",
        "\n",
        "def get_feature_neutral_mean(df):\n",
        "    feature_cols = [c for c in df.columns if c.startswith(\"feature\")]\n",
        "    df.loc[:, \"neutral_sub\"] = neutralize(df, [PREDICTION_NAME],\n",
        "                                          feature_cols)[PREDICTION_NAME]\n",
        "    scores = df.groupby(\"era\").apply(\n",
        "        lambda x: np.corrcoef(x[\"neutral_sub\"].rank(pct=True, method=\"first\"), x[TARGET_NAME])).mean()\n",
        "    return np.mean(scores)\n",
        "\n",
        "def compute_val_mmc(valid_df : pd.DataFrame):    \n",
        "    # MMC over validation\n",
        "    mmc_scores = []\n",
        "    corr_scores = []\n",
        "    for _, x in valid_df.groupby(\"era\"):\n",
        "        series = neutralize_series(pd.Series(unif(x[PREDICTION_NAME])),\n",
        "                                   pd.Series(unif(x[EXAMPLE_PRED])))\n",
        "        mmc_scores.append(np.cov(series, x[TARGET_NAME])[0, 1] / (0.29 ** 2)) # I have no idea what htis line does (0.29 ** 2)\n",
        "        corr_scores.append(np.corrcoef(unif(x[PREDICTION_NAME]).rank(pct=True, method=\"first\"), x[TARGET_NAME]))\n",
        "\n",
        "    val_mmc_mean = np.mean(mmc_scores)\n",
        "    val_mmc_std = np.std(mmc_scores)\n",
        "    val_mmc_sharpe = val_mmc_mean / val_mmc_std\n",
        "    corr_plus_mmcs = [c + m for c, m in zip(corr_scores, mmc_scores)]\n",
        "    corr_plus_mmc_sharpe = np.mean(corr_plus_mmcs) / np.std(corr_plus_mmcs)\n",
        "    corr_plus_mmc_mean = np.mean(corr_plus_mmcs)\n",
        "\n",
        "    #print(\"MMC Mean = {:.6f}, MMC Std = {:.6f}, CORR+MMC Sharpe = {:.4f}\".format(val_mmc_mean, val_mmc_std, corr_plus_mmc_sharpe))\n",
        "\n",
        "    # Check correlation with example predictions\n",
        "    corr_with_example_preds = np.corrcoef(valid_df[EXAMPLE_PRED].rank(pct=True, method=\"first\"),\n",
        "                                          valid_df[PREDICTION_NAME].rank(pct=True, method=\"first\"))[0, 1]\n",
        "    #print(\"Corr with example preds: {:.4f}\".format(corr_with_example_preds))\n",
        "    \n",
        "    return val_mmc_mean, val_mmc_std, corr_plus_mmc_sharpe, corr_with_example_preds\n",
        "\n",
        "\n",
        "# this is the main method. The rest are just called interanlly. \n",
        "def score_summary(valid_df : pd.DataFrame):\n",
        "    score_dict = {}\n",
        "    \n",
        "    try:\n",
        "        score_dict['correlation'] = compute_val_corr(valid_df)\n",
        "    except:\n",
        "        print('ERR: computing correlation')\n",
        "    try:\n",
        "        score_dict['corr_sharpe'], score_dict['corr_mean'], score_dict['corr_std'], score_dict['max_drawdown'] = compute_val_sharpe(valid_df)\n",
        "    except:\n",
        "        print('ERR: computing sharpe')\n",
        "    try:\n",
        "        score_dict['feature_exposure'], score_dict['max_feature_exposure'] = compute_val_feature_exposure(valid_df)\n",
        "    except:\n",
        "        print('ERR: computing feature exposure')\n",
        "    # try:\n",
        "    #     score_dict['mmc_mean'], score_dict['mmc_std'], score_dict['corr_mmc_sharpe'], score_dict['corr_with_example_xgb'] = compute_val_mmc(valid_df)\n",
        "    # except:\n",
        "    #     print('ERR: computing MMC')\n",
        "    \n",
        "    return score_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZlvD8U4bv072"
      },
      "outputs": [],
      "source": [
        "def look_at_best_models_so_far():\n",
        "  df = load_saved_params()\n",
        "  filter = df['correlation'] >.02\n",
        "  best = df[filter].sort_values(by ='correlation', ascending=False).head(20)\n",
        "  best.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lBD0oUmBWzx"
      },
      "source": [
        "### Command and cotrol methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "80k6-VBtBWhf"
      },
      "outputs": [],
      "source": [
        "def train_validate_store(params:dict, train_data: pd.DataFrame, validation_data: pd.DataFrame):\r\n",
        "  \"\"\"\r\n",
        "    Create a LGBM model based on the hyper paramters in params trained on train_data.\r\n",
        "    Compute validation scores from the validation_data.\r\n",
        "    Append the hyperparams and scores to a .csv file in your Google Drive.\r\n",
        "    Silent: a boolean if you want to see a CORR score for this call\r\n",
        "  \"\"\"\r\n",
        "  start_time = datetime.datetime.now()\r\n",
        "  my_model = train_LGBMRegressor(params=params, train_data=train_data)\r\n",
        "  my_predictions = my_model.predict(validation_data[FEATURES])\r\n",
        "  valid_df = valid4score(validation_data, my_predictions, load_example=False, save=False)\r\n",
        "  my_scores = score_summary(valid_df)\r\n",
        "  my_total_time = (datetime.datetime.now() - start_time).total_seconds() \r\n",
        "  my_model_stats = ModelStats(model=my_model, scores=my_scores, total_time=my_total_time)\r\n",
        "  my_model_stats.save_hyperparams_scores_to_google_drive_tabular()\r\n",
        "  print(round(my_model_stats.scores['correlation'], 4), end=' ')\r\n",
        "  print(round(my_model_stats.scores['corr_sharpe'], 4))\r\n",
        "\r\n",
        "def load_saved_params():\r\n",
        "  return pd.read_csv(PATH_TO_SAVE_SCORES)\r\n",
        "\r\n",
        "\r\n",
        "def create_score_summary(model):\r\n",
        "  my_predictions = model.predict(VALIDATION_DATA[FEATURES])\r\n",
        "  valid_df = valid4score(VALIDATION_DATA, my_predictions, load_example=False, save=False)\r\n",
        "  return score_summary(valid_df)\r\n",
        "\r\n",
        "\r\n",
        "def generate_param_set():\r\n",
        "  \"\"\"\r\n",
        "  Create a set of hyper parameters to test on the validation data.  \r\n",
        "  Returns a list of dictionaries\r\n",
        "  \"\"\"\r\n",
        "  param_set=[]\r\n",
        "  for i in range(20):\r\n",
        "      for n_estimators in range(2800,4000,100):\r\n",
        "          param_set.append({\r\n",
        "                'n_estimators': n_estimators,\r\n",
        "                'objective': 'regression',\r\n",
        "                'boosting_type': 'gbdt',\r\n",
        "                'max_depth': 4,\r\n",
        "                'learning_rate': round(np.random.uniform(.02,.05),3),\r\n",
        "                'feature_fraction': round(np.random.uniform(0.1,.4),3), \r\n",
        "                'seed': 42 # exhaustive study has proven this to be the best possible seed. (joke)\r\n",
        "                  })\r\n",
        "  \r\n",
        "  return param_set\r\n",
        "\r\n",
        "\r\n",
        "def explore_lgbm():\r\n",
        "  \"\"\"\r\n",
        "    The main function to explore the hyper parameter space on the current data.\r\n",
        "  \"\"\"\r\n",
        "  param_set = generate_param_set()\r\n",
        "  for index, param in enumerate(param_set):\r\n",
        "    train_validate_store(param,TRAINING_DATA,VALIDATION_DATA)\r\n",
        "    print(f'Completed {index} models of {len(param_set)}')\r\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyHk97VIYFdj",
        "outputId": "f2e49cf5-b5ed-4b04-8735-c08c32a01cef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.18, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.18\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] File  does not exist: ''",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-10-248c702b24d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mexplore_lgbm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-9-cf08428081b2>\u001b[0m in \u001b[0;36mexplore_lgbm\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m   \u001b[0mparam_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_param_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0mtrain_validate_store\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTRAINING_DATA\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mVALIDATION_DATA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Completed {index} models of {len(param_set)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-9-cf08428081b2>\u001b[0m in \u001b[0;36mtrain_validate_store\u001b[1;34m(params, train_data, validation_data)\u001b[0m\n\u001b[0;32m     13\u001b[0m   \u001b[0mmy_total_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m   \u001b[0mmy_model_stats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelStats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmy_total_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m   \u001b[0mmy_model_stats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_hyperparams_scores_to_google_drive_tabular\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_model_stats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'correlation'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_model_stats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'corr_sharpe'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-6-568889b8def5>\u001b[0m in \u001b[0;36msave_hyperparams_scores_to_google_drive_tabular\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_params_scores_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m# try to load that current df into memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mdisk_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH_TO_SAVE_SCORES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;31m#print(f'Read in new saved scores with {disk_df.shape} shape')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mnew_updated_disk_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmerge_dfs_horizontally\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdisk_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams_scores_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File  does not exist: ''"
          ]
        }
      ],
      "source": [
        "explore_lgbm()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x1Van5HwCHc"
      },
      "source": [
        "## Custom Loss functions\n",
        "\n",
        "Broad Goals:\n",
        "\n",
        "1. Increase Sharpe. (currently ~.9\n",
        "2. Decrease Validation CORR standard Deviation ( currently 0.0265)\n",
        "3. Decrease Feature exposure (currently .26 )\n",
        "\n",
        "\n",
        "\n",
        "What an abstract class would look like\n",
        "\n",
        "abstract class custom_train_loss_eval_function(y_true: np.Array, y_pred: np.Array):\n",
        "\n",
        "# it seems like there are 50k examples where the errror is always extreme You should figure out if there are any patterns there"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ym0A8ZCa0Esr"
      },
      "outputs": [],
      "source": [
        "# source: https://towardsdatascience.com/custom-loss-functions-for-gradient-boosting-f79c1b40466d | April 2021\r\n",
        "# and https://github.com/manifoldai/mf-eng-public/blob/master/notebooks/custom_loss_lightgbm.ipynb | April 2021\r\n",
        "\r\n",
        "\r\n",
        "# my local copy of the notebook I am using as a tutorial https://colab.research.google.com/drive/1GZjZw3uJ3dyb_QhQZf0U7HjMKyznFp-B#scrollTo=JfAlK75Q4MlJ\r\n",
        "\r\n",
        "\r\n",
        "# This makes overestimates much more expensive than underestimates.\r\n",
        "# you should set up an inheritace strucure for the absract class of training_evaluators\r\n",
        "#I expect this to just make the model worse but is to make sure I can do it before testign more\r\n",
        "def custom_asymmetric_train(y_true, y_pred):\r\n",
        "  scaler = 1\r\n",
        "  residual = (y_true - y_pred).astype(\"float\")\r\n",
        "  grad = np.where(residual<0, -2*scaler*residual, -2*residual)\r\n",
        "  hess = np.where(residual<0, 2*scaler, 2.0)\r\n",
        "  return grad, hess\r\n",
        "\r\n",
        "def custom_bias_against_extreme_train(y_true, y_pred):\r\n",
        "  \"\"\"\r\n",
        "  if the squared differnce is more thanEXTREME_THRESHOLD\r\n",
        "  incrase the gradient and hessian by the scaler.\r\n",
        "\r\n",
        "  Just theory but very interesting. Right now this is just worse than otherwise\r\n",
        "\r\n",
        "\r\n",
        "  # each round you can print the composition of errors\r\n",
        "  \"\"\"\r\n",
        "  EXTREME_THRESHOLD = .1 # constant for what \"extremeness\" means\r\n",
        "  scaler =1\r\n",
        "  residual = (y_true - y_pred).astype(\"float\")\r\n",
        "  grad = np.where(residual**2 > EXTREME_THRESHOLD, -2*scaler*residual, -2*residual)\r\n",
        "  hess = np.where(residual**2 > EXTREME_THRESHOLD, 2.1*scaler, 2.0)\r\n",
        "  error_targets = y_true[(residual**2 > EXTREME_THRESHOLD)]\r\n",
        "\r\n",
        "##################\r\n",
        " # You can do rank corrilation at each iteration. or any other kind of analysis\r\n",
        "\r\n",
        " # you might want to rework it into a categorization problem where the results of the regression are the weighted average likihoods of each oucome. (could limit ot only 2 adject ) \r\n",
        "#############\r\n",
        "\r\n",
        "  print(f'Average squared residual {np.average(residual**2)} count of extreme condition {(residual**2 > EXTREME_THRESHOLD).sum()} Error targets avg{error_targets.mean()} ', end='') # You can use this to see the residual o ver \r\n",
        "  print(f'Error targets Mean{error_targets.mean()}Error targets mode{error_targets.mode()}')\r\n",
        "  #print(f'Describe error targets {error_targets.value_counts().to_dict()}')\r\n",
        "  \r\n",
        "\r\n",
        "  return grad, hess\r\n",
        "\r\n",
        "def create_custom_loss_model():\r\n",
        "  \"\"\"\r\n",
        "    Train a lightGBM model with a custom loss function\r\n",
        "    # figure out the syntax to pass this function another function in python\r\n",
        "  \"\"\"\r\n",
        "  custom_loss_model = lightgbm.LGBMRegressor(random_state=33)\r\n",
        "  custom_loss_model.set_params(**{'n_estimators':50,'objective': custom_bias_against_extreme_train})\r\n",
        "  # you need to include some ways to do early stopping \r\n",
        "  custom_loss_model.fit(\r\n",
        "      TRAINING_DATA[FEATURES],\r\n",
        "      TRAINING_DATA[TARGET],\r\n",
        "  )\r\n",
        "  return custom_loss_model\r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WIkAxCho7O4T"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# custom_loss_model = create_custom_loss_model()\n",
        "# custom_scores = create_score_summary(custom_loss_model)\n",
        "# print(custom_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RM107nhZF_ur"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf0BRd77fZMA"
      },
      "source": [
        "# Debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "o3BUVpxMwQza"
      },
      "outputs": [],
      "source": [
        "def create_default_model():\n",
        "  \"\"\"\n",
        "  Returns the model used for debugging. This is the point of compaison everything needs to beat.\n",
        "  \"\"\"\n",
        "  default_params = {\n",
        "                'n_estimators': 100,\n",
        "                'objective': 'regression',\n",
        "                'boosting_type': 'gbdt',\n",
        "                'max_depth': 4,\n",
        "                'learning_rate': .02,\n",
        "                'feature_fraction': .25, \n",
        "                'seed': 3\n",
        "                  }\n",
        "  model = train_LGBMRegressor(params=default_params, train_data=TRAINING_DATA)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "75ZV54AMzMiE"
      },
      "outputs": [],
      "source": [
        "default_model = create_default_model()\n",
        "default_scores = create_score_summary(default_model)\n",
        "default_scores\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "b364c12-MiKD"
      ],
      "machine_shape": "hm",
      "name": "Refactored Max Datapoints.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 64-bit (conda)",
      "name": "python383jvsc74a57bd05f55334c0ec2b6b265735cb6e4e448fe59a4ec2646b0eb29ab8c6a2d945064a9"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}