{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Score Calc on colab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fvB7bsbhgAnW"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf0mcGT2fzIT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ScoreCalculator:\n",
        "    \"\"\"\n",
        "        Calcuating various metrics on the relationship between your predictions, example predictions and validation data.\n",
        "        Call compute_numerai_diagnostics(a pd.Series of your predictions on the validation data)\n",
        "        Add method to compute more differnent diagonistcs\n",
        "        Currently not throughly tested.\n",
        "        Primarily based on: example.py \n",
        "    \"\"\"\n",
        "    def __init__(self, validation_data, example_preds):\n",
        "        self.validation_data = validation_data\n",
        "        self._rank_normalized_validation_targets = validation_data['rank_target'] \n",
        "        self._feature_col_names = [column_name for column_name in self.validation_data.columns if 'feature' in column_name]\n",
        "        self.example_predictions = example_preds\n",
        "        self._rank_normalized_example_predictions = example_preds['rank_example_prediction'] # hardcoded\n",
        "    \n",
        "    def score(self, df: pd.DataFrame)-> float:\n",
        "        \"\"\"\n",
        "          # You should replace with lambda for speed\n",
        "            utility to compute corr on a grouping of self._validation_data \n",
        "        \"\"\"\n",
        "        return _compute_corr(df['rank_target'], df['rank_prediction'])\n",
        "\n",
        "    # suspect\n",
        "    def richards_dependence(self, df, target_col, era_col, prediction_col) -> float: \n",
        "        \"\"\"\n",
        "            Measures the independendence of prediction with the targets\n",
        "            \n",
        "            Currently unused \n",
        "            example call:\n",
        "            richards_dependence(df, 'target', 'era', 'prediction'))\n",
        "            Source: Numerai Forumn user:richai @ https://forum.numer.ai/t/independence-and-sharpe/2560 | May 3 ,2021\n",
        "        \"\"\"  \n",
        "        scores_by_era = df.groupby(era_col).apply(lambda d: d[[prediction_col, target_col]].corr()[target_col][0])\n",
        "            \n",
        "        # these need to be ranked within era so \"error\" makes sense\n",
        "        df[prediction_col] = df.groupby(era_col)[prediction_col].rank(pct=True)\n",
        "        df[target_col] = df.groupby(era_col)[target_col].rank(pct=True)\n",
        "\n",
        "        df[\"era_score\"] = df[era_col].map(scores_by_era)\n",
        "\n",
        "        df[\"error\"] = (df[target_col] - df[prediction_col]) ** 2\n",
        "        df[\"1-error\"] = 1 - df[\"error\"]\n",
        "\n",
        "        # Returns the correlation of the 1-error with the era_score\n",
        "        # i.e. how dependent/correlated each prediction is with its era_score\n",
        "        return df[[\"1-error\", \"era_score\"]].corr()[\"era_score\"][0]\n",
        "\n",
        "\n",
        "    def rank_noramalize_series(self, col:pd.Series)-> pd.Series:\n",
        "        \"\"\"\n",
        "            Compute the rank ordering of col. Scale each element of col between 0 and 1 based on their relative size\n",
        "            Returns: a pd.Series\n",
        "        \"\"\" \n",
        "        scaled_col = (col.rank(method=\"first\") - 0.5) / len(col)\n",
        "        scaled_col.index = col.index\n",
        "        return scaled_col\n",
        "\n",
        " \n",
        "    def compute_validation_corr(self)-> float:\n",
        "        \"\"\"\n",
        "            pred: your predictions on the validation data.\n",
        "            Compute your corr on the validation data.\n",
        "            # need to call add_predictions_to_validation_df() before you call this or it will throw an derror\n",
        "        \"\"\"\n",
        "        ranked_targets = self.validation_data['rank_target']\n",
        "        ranked_preds = self.validation_data['rank_prediction']\n",
        "        return self._compute_corr(ranked_targets, ranked_preds)\n",
        "\n",
        "\n",
        "    def _compute_corr(self, a: pd.Series, b: pd.Series )->float:\n",
        "        \"\"\"\n",
        "            Returns np.corrcoef on a and b. pass this only ranked correlations\n",
        "        \"\"\"\n",
        "        return np.corrcoef(a, b)[0, 1] # not ranked \n",
        "\n",
        "\n",
        "    def compute_validation_std(self) -> float:\n",
        "      \"\"\"\n",
        "          Returns the Standard Deviation of corr by era.\n",
        "      \"\"\"\n",
        "      return self.create_per_era_grouper().std()\n",
        "\n",
        "    def compute_validation_per_era_mean_corr(self)-> float:\n",
        "      \"\"\"\n",
        "      Returns the mean corr by era.\n",
        "      \"\"\"\n",
        "      return self.create_per_era_grouper().mean()\n",
        "\n",
        "    def create_per_era_grouper(self) -> pd.Series:\n",
        "      \"\"\"\n",
        "        Returns an array of era, Corr on validation targets for that era.\n",
        "      \"\"\"\n",
        "      return self.validation_data.groupby(\"era\").apply(lambda df: np.corrcoef(df['rank_target'], df['rank_prediction'])[0][1])\n",
        "\n",
        "    def compute_validation_sharpe(self)-> float:\n",
        "        \"\"\"\n",
        "            Computes your sharpe corr socre on each era \n",
        "            sharpe = average corr per era / std dev of corr per era. \n",
        "        \"\"\"\n",
        "        per_era_corr_grouper = self.create_per_era_grouper()\n",
        "        mean_per_era_corr = per_era_corr_grouper.mean()\n",
        "        std_per_era_corr = per_era_corr_grouper.std()\n",
        "        return mean_per_era_corr / std_per_era_corr\n",
        "        \n",
        "\n",
        "    def compute_max_drawdown(self)-> float:\n",
        "        \"\"\"\n",
        "            Copied from Numerai's example_model.py\n",
        "            Max drawdown is the \"largest cumulative decrease between any two eras in terms of validation correlation\"\n",
        "            In short this keeps a running total of corr between eras. Then it find the length of the largest decrease and returns that number. \n",
        "            Is an estimate of risk\n",
        "        \"\"\"\n",
        "        validation_correlations = self.create_per_era_grouper() # this needs to be stored in the class variables do avoid doing it twice\n",
        "        rolling_max = (validation_correlations + 1).cumprod().rolling(window=100, min_periods=1).max()                                                           \n",
        "        daily_value = (validation_correlations + 1).cumprod()\n",
        "        max_drawdown = -(rolling_max - daily_value).max()\n",
        "        return max_drawdown\n",
        "\n",
        "\n",
        "    def compute_feature_exposure(self)-> float:\n",
        "        \"\"\"\n",
        "            The maximum corrilatiosn your predictions have with any single feature\n",
        "            Copied from Numerai's example_model.py\n",
        "        \"\"\"\n",
        "        # pred_valid_df = self.validation_data # unclear if the default to \n",
        "        # pred_valid_df['prediction'] = rank_noramalize_series(pred) # add prediction column\n",
        "\n",
        "        # feature_names = [f for f in self.validation_data.columns if f.startswith(\"feature\")]\n",
        "        # feature_exposures = validation_data[feature_names].apply(lambda d: correlation(pred_valid_df['prediction'], d), axis=0) # axis =0 means by columns\n",
        "        feature_exposures = []\n",
        "        for col in self._feature_col_names:\n",
        "          feature_exposure_for_col = self._compute_corr(self.validation_data[col], self.validation_data['prediction']) # does feature exposrue look at rank corr \n",
        "          feature_exposures.append(feature_exposure_for_col)\n",
        "                                                             \n",
        "        max_feature_exposure = np.max(np.abs(np.array(feature_exposures)))\n",
        "        return max_feature_exposure\n",
        "\n",
        "        # I don't understand this\n",
        "    def compute_feature_neutral_corr_mean(self, pred:pd.Series)-> float:\n",
        "        \"\"\"\n",
        "            The mean of your per era correlation after your predictions have been neutralized to all the features\n",
        "            Copied from Numerai's example_model.py\n",
        "        \"\"\"\n",
        "        pred_valid_df = self.validation_data # unclear if the default to \n",
        "        pred_valid_df['prediction'] = rank_noramalize_series(pred) # add prediction column\n",
        "\n",
        "        feature_cols = [c for c in df.columns if c.startswith(\"feature\")]\n",
        "        pred_valid_df.loc[:, \"neutral_sub\"] = neutralize(pred_valid_df, ['prediction'],\n",
        "                                            feature_cols)['prediction']\n",
        "        \n",
        "        # I the rank normalize within the lambda\n",
        "        scores = df.groupby(\"era\").apply(\n",
        "            lambda x: self._compute_corr(rank_noramalize_series(x[\"neutral_sub\"]), rank_noramalize_series(x['target']))).mean()\n",
        "        return np.mean(scores)\n",
        "\n",
        "    #suspect\n",
        "    def neutralize(self, df, columns, by, proportion=1.0):\n",
        "        \"\"\"\n",
        "            Copied as is from example_model.py\n",
        "        \"\"\"\n",
        "        scores = df.loc[:, columns]\n",
        "        exposures = df[by].values\n",
        "\n",
        "        # constant column to make sure the series is completely neutral to exposures\n",
        "        exposures = np.hstack(\n",
        "            (exposures,\n",
        "            np.asarray(np.mean(scores)) * np.ones(len(exposures)).reshape(-1, 1)))\n",
        "\n",
        "        scores = scores - proportion * exposures.dot(\n",
        "            np.linalg.pinv(exposures).dot(scores))\n",
        "        return scores / scores.std()\n",
        "    \n",
        "    #suspect\n",
        "    def compute_mmc_stats(self, pred:pd.Series) -> tuple:\n",
        "        \"\"\"\n",
        "            Using example predictions as an estimate for the meta model, compute mmc stats\n",
        "            Copied from example_model.py\n",
        "            returns val_mmc_mean, corr_plus_mmc_sharpe, \n",
        "\n",
        "            Not refractored. Copied as is. Only variable and function names are changed\n",
        "\n",
        "        \"\"\"\n",
        "        pred_valid_df = self.validation_data # unclear if the default to \n",
        "        pred_valid_df['prediction'] = rank_noramalize_series(pred) # add prediction column\n",
        "        pred_valid_df['ExamplePreds'] = self.example_predictions\n",
        "        mmc_scores = []\n",
        "        corr_scores = []\n",
        "\n",
        "        for _, x in validation_data.groupby(\"era\"):\n",
        "            series = self.neutralize_series(pd.Series(self.rank_noramalize_series(x['prediction'])),\n",
        "                                    pd.Series(self.rank_noramalize_series(x[\"ExamplePreds\"])))\n",
        "            mmc_scores.append(np.cov(series, x['target'])[0, 1] / (0.29 ** 2))\n",
        "            corr_scores.append(correlation(self.rank_noramalize_series(x['prediction']), x['target']))\n",
        "\n",
        "        val_mmc_mean = np.mean(mmc_scores)\n",
        "        val_mmc_std = np.std(mmc_scores)\n",
        "        val_mmc_sharpe = val_mmc_mean / val_mmc_std\n",
        "        corr_plus_mmcs = [c + m for c, m in zip(corr_scores, mmc_scores)]\n",
        "        corr_plus_mmc_sharpe = np.mean(corr_plus_mmcs) / np.std(corr_plus_mmcs)\n",
        "        corr_plus_mmc_mean = np.mean(corr_plus_mmcs)\n",
        "        #corr_plus_mmc_sharpe_diff = corr_plus_mmc_sharpe - validation_sharpe\n",
        "\n",
        "        # print(\n",
        "        #     f\"MMC Mean: {val_mmc_mean}\\n\"\n",
        "        #     f\"Corr Plus MMC Sharpe:{corr_plus_mmc_sharpe}\\n\"\n",
        "        #     f\"Corr Plus MMC Diff:{corr_plus_mmc_sharpe_diff}\"\n",
        "        # )\n",
        "        return  val_mmc_mean, corr_plus_mmc_sharpe, \n",
        "\n",
        "    #suspect\n",
        "    def neutralize_series(self, series, by, proportion=1.0):\n",
        "        \"\"\"\n",
        "            Copied from example_model.py\n",
        "            not refactored\n",
        "        \"\"\"\n",
        "        scores = series.values.reshape(-1, 1)\n",
        "        exposures = by.values.reshape(-1, 1)\n",
        "\n",
        "        # this line makes series neutral to a constant column so that it's centered and for sure gets corr 0 with exposures\n",
        "        exposures = np.hstack(\n",
        "            (exposures,\n",
        "            np.array([np.mean(series)] * len(exposures)).reshape(-1, 1)))\n",
        "\n",
        "        correction = proportion * (exposures.dot(\n",
        "            np.linalg.lstsq(exposures, scores, rcond=None)[0]))\n",
        "        corrected_scores = scores - correction\n",
        "        neutralized = pd.Series(corrected_scores.ravel(), index=series.index)\n",
        "        return neutralized\n",
        "\n",
        "    \n",
        "    def compute_corr_with_example_preds(self, tournament_pred:pd.DataFrame) -> float:\n",
        "        \"\"\"\n",
        "            Compute the rank corrilation between your tournament_pred and the example predictions\n",
        "            tournament_pred: pd.DataFrame must have 'rank_prediction' column\n",
        "            WORKS \n",
        "        \"\"\"\n",
        "        return self._compute_corr(tournament_pred['rank_prediction'], self._rank_normalized_example_predictions)\n",
        "    \n",
        "      # replace very bad\n",
        "    def merge_pred_valid_df(self,pred: pd.Series) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "            Add your predictions to self.validation_data in order to make calcuating the answers more efficnet \n",
        "        \"\"\"\n",
        "        pred_valid_df = self.validation_data # unclear if the default to \n",
        "        pred_valid_df['prediction'] = rank_noramalize_series(pred)\n",
        "        return pred_valid_df        \n",
        "\n",
        "    # repalced by \n",
        "    def compute_per_era_corr(self, pred: pd.Series) -> list:\n",
        "        \"\"\"\n",
        "            Returns a list of tuples for representing (era, corr for era)\n",
        "        \"\"\"\n",
        "        pred_valid_df = self.merge_pred_valid_df(pred)\n",
        "        era_corr_list = []\n",
        "        eras = list(pred_valid_df['era'].unique())\n",
        "        for era in eras:\n",
        "            local_era_targets = np.array(valid_df[valid_df['era'] == era]['target'])\n",
        "            local_era_predictions = np.array(valid_df[valid_df['era'] == era]['prediction'])\n",
        "            era_corr = self._compute_corr(local_era_targets, local_era_predictions)\n",
        "            era_corr_list.append((era,era_corr))\n",
        "        \n",
        "        return era_corr_list\n",
        "\n",
        "    # this is the main method that you call on your validation predictions\n",
        "    # my_score_calculator = ScoreCalculator()\n",
        "    # scores =my_score_calculator.compute_numerai_diagnostics(my_model.predict(validation_data[features]))\n",
        "    # print(scores)\n",
        "\n",
        "    def add_predictions_to_validation_df(self, tournament_preds:pd.DataFrame) -> None:\n",
        "      \"\"\"\n",
        "        updates the self.validation_df with your prediction in tournament_predss\n",
        "        tournament_df: pd.DataFrame Your predictions for this round.\n",
        "        Must have index = 'id'\n",
        "        Must have column 'prediction' \n",
        "      \"\"\"\n",
        "      valid_ids = self.validation_data.index # get all the ids with the valaidatino data\n",
        "      preds_on_valid_data = tournament_preds.loc[valid_ids,:] # subset on the validation data\n",
        "      self.validation_data['prediction'] = preds_on_valid_data['prediction']\n",
        "      rows = self.validation_data.shape[0]\n",
        "      self.validation_data['rank_prediction'] = self.validation_data['prediction'].rank() / rows\n",
        "      return\n",
        "    \n",
        "    def compute_numerai_diagnostics(self, preds: pd.DataFrame):\n",
        "      \"\"\"\n",
        "          Return a dataframe that is equivalent to the diagnostics tab on numerai\n",
        "          preds: A dataframe of your model's prediction accross the entire live tournament data for this round.\n",
        "            Must have index='id'\n",
        "                      columns = \n",
        "      \"\"\"\n",
        "      self.add_predictions_to_validation_df(tournament_preds)\n",
        "      diagnostics_df = pd.DataFrame()\n",
        "      diagnostics_df['valid_sharpe'] = [self.compute_validation_sharpe()]\n",
        "      diagnostics_df['valid_corr'] = [self.compute_validation_corr()]\n",
        "      #diagnostics_df['valid_FNC'] = [self.compute_feature_neutral_corr_mean(tournament_preds)] # hard copied as is from example_model.py\n",
        "\n",
        "      diagnostics_df['valid_SD'] = [self.compute_validation_std()]\n",
        "      diagnostics_df['feature_exposure'] = [self.compute_feature_exposure()]\n",
        "      diagnostics_df['max_drawdown'] = [self.compute_max_drawdown()]\n",
        "\n",
        "      #val_mmc_mean, corr_plus_mmc_sharpe = self.compute_mmc_stats(tournament_preds) # Hard copied as is from example_model.py\n",
        "\n",
        "      #diagnostics_df['corr_plus_MMC_sharpe'] = [corr_plus_mmc_sharpe]\n",
        "      #diagnostics_df['MMC_mean '] = [val_mmc_mean]\n",
        "      diagnostics_df['corr_with_example_preds '] = [self.compute_corr_with_example_preds(preds)]\n",
        "      return diagnostics_df\n",
        "\n"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvB7bsbhgAnW"
      },
      "source": [
        "## Class to ping scores. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G2EHwZVgDZO"
      },
      "source": [
        "class NumeraiDataLoader:\n",
        "  \"\"\"\n",
        "      Pings and cleans the data from Numerai\n",
        "  \"\"\"\n",
        "  def ping_validation_data(self) -> pd.DataFrame:\n",
        "            \"\"\"\n",
        "            Ping Numerai to create get the live tournament data and extact all the validation data.\n",
        "\n",
        "            Adapted from : https://www.kaggle.com/code1110/numerai-tournament | May 3, 2021\n",
        "            \"\"\"\n",
        "            tournament_data_url = 'https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_tournament_data.csv.xz'\n",
        "            tournament_df = pd.read_csv(tournament_data_url)\n",
        "            valid_df = tournament_df[tournament_df[\"data_type\"] == \"validation\"].reset_index(drop = True)\n",
        "            feature_cols = valid_df.columns[valid_df.columns.str.startswith('feature')]\n",
        "\n",
        "            map_floats_to_ints = {0.0 : 0, 0.25 : 1, 0.5 : 2, 0.75 : 3, 1.0 : 4}\n",
        "            for col in feature_cols:\n",
        "                valid_df[col] = valid_df[col].map(map_floats_to_ints).astype(np.uint8) # reduce space costs by casting features as ints\n",
        "                \n",
        "            valid_df[\"era\"] = valid_df[\"era\"].apply(lambda x: int(x[3:])) # strip the word 'era' from the era column\n",
        "            valid_df.drop(columns=[\"data_type\"], inplace=True)\n",
        "\n",
        "            total_valid_rows = valid_df.shape[0]\n",
        "            valid_df['rank_target'] = valid_df['target'].rank(method='first') / total_valid_rows\n",
        "            valid_df.set_index('id', inplace=True)\n",
        "            return valid_df\n",
        "\n",
        "        # called during init # broken You need to specify that this is example preds over the entire df\n",
        "  def ping_example_predictions(self)-> pd.DataFrame:\n",
        "      \"\"\"\n",
        "          Create a dataframe of Id, Prediction, rank_prediction, where Id, is the id column in tournament_data.csv prediction is the numerai provided example model, and rank_prediction is the normalized prediction target\n",
        "         \t                  prediction  rank_prediction\n",
        "          id\t\t\n",
        "          n0003aa52cab36c2\t0.49\t0.097334\n",
        "          n000920ed083903f\t0.49\t0.097335\n",
        "          n0038e640522c4a6\t0.53\t0.969455\n",
        "          n004ac94a87dc54b\t0.51\t0.656894\n",
        "          n0052fe97ea0c05f\t0.50\t0.332613\n",
        "      \"\"\"\n",
        "      example_predictions_url = \"https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_example_predictions_data.csv.xz\"\n",
        "      example_preds =  pd.read_csv(example_predictions_url, index_col=0)\n",
        "      total_example_prediction_rows = example_preds.shape[0]\n",
        "      example_preds['rank_example_prediction'] = example_preds['prediction'].rank(method='first') / total_example_prediction_rows\n",
        "      return example_preds\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onM80O8sj7j9"
      },
      "source": [
        "### tester"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6yVBBx0gce-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5cfe6a5-677c-452b-bd06-c342790ee343"
      },
      "source": [
        "myLoader = NumeraiDataLoader()\n",
        "\n",
        "validation_data = myLoader.ping_validation_data()\n",
        "print(validation_data.head())\n",
        "print(validation_data.shape)\n",
        "\n",
        "example_preds = myLoader.ping_example_predictions()\n",
        "print(example_preds.head())\n",
        "print(example_preds.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  era  feature_intelligence1  ...  target  rank_target\n",
            "id                                            ...                     \n",
            "n0003aa52cab36c2  121                      1  ...    0.25     0.049935\n",
            "n000920ed083903f  121                      3  ...    0.50     0.249755\n",
            "n0038e640522c4a6  121                      4  ...    1.00     0.950058\n",
            "n004ac94a87dc54b  121                      3  ...    0.50     0.249762\n",
            "n0052fe97ea0c05f  121                      1  ...    0.75     0.750223\n",
            "\n",
            "[5 rows x 313 columns]\n",
            "(137779, 313)\n",
            "                  prediction  rank_example_prediction\n",
            "id                                                   \n",
            "n0003aa52cab36c2        0.49                 0.097334\n",
            "n000920ed083903f        0.49                 0.097335\n",
            "n0038e640522c4a6        0.53                 0.969455\n",
            "n004ac94a87dc54b        0.51                 0.656894\n",
            "n0052fe97ea0c05f        0.50                 0.332613\n",
            "(1714763, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROAYPsPXrghu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "86ae6a09-6d8d-46d5-9880-6833773b3db7"
      },
      "source": [
        "\n",
        "tournament_preds = np.cos(example_preds)\n",
        "tournament_preds_rows = tournament_preds.shape[0]\n",
        "tournament_preds['rank_prediction'] = tournament_preds['prediction'].rank(method='first') / tournament_preds_rows\n",
        "\n",
        "tournament_preds"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prediction</th>\n",
              "      <th>rank_example_prediction</th>\n",
              "      <th>rank_prediction</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>n0003aa52cab36c2</th>\n",
              "      <td>0.882333</td>\n",
              "      <td>0.995267</td>\n",
              "      <td>0.667388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n000920ed083903f</th>\n",
              "      <td>0.882333</td>\n",
              "      <td>0.995267</td>\n",
              "      <td>0.667389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n0038e640522c4a6</th>\n",
              "      <td>0.862807</td>\n",
              "      <td>0.565749</td>\n",
              "      <td>0.005497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n004ac94a87dc54b</th>\n",
              "      <td>0.872745</td>\n",
              "      <td>0.791893</td>\n",
              "      <td>0.120487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n0052fe97ea0c05f</th>\n",
              "      <td>0.877583</td>\n",
              "      <td>0.945192</td>\n",
              "      <td>0.343107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nffa71c03a5a27a2</th>\n",
              "      <td>0.877583</td>\n",
              "      <td>0.791894</td>\n",
              "      <td>0.667387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nffd391982772aeb</th>\n",
              "      <td>0.877583</td>\n",
              "      <td>0.791893</td>\n",
              "      <td>0.667388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nffda15ceb83f190</th>\n",
              "      <td>0.872745</td>\n",
              "      <td>0.637527</td>\n",
              "      <td>0.343106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nffda7325b750430</th>\n",
              "      <td>0.872745</td>\n",
              "      <td>0.637526</td>\n",
              "      <td>0.343107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nfffb06812158e00</th>\n",
              "      <td>0.882333</td>\n",
              "      <td>0.945193</td>\n",
              "      <td>0.902666</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1714763 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  prediction  rank_example_prediction  rank_prediction\n",
              "id                                                                    \n",
              "n0003aa52cab36c2    0.882333                 0.995267         0.667388\n",
              "n000920ed083903f    0.882333                 0.995267         0.667389\n",
              "n0038e640522c4a6    0.862807                 0.565749         0.005497\n",
              "n004ac94a87dc54b    0.872745                 0.791893         0.120487\n",
              "n0052fe97ea0c05f    0.877583                 0.945192         0.343107\n",
              "...                      ...                      ...              ...\n",
              "nffa71c03a5a27a2    0.877583                 0.791894         0.667387\n",
              "nffd391982772aeb    0.877583                 0.791893         0.667388\n",
              "nffda15ceb83f190    0.872745                 0.637527         0.343106\n",
              "nffda7325b750430    0.872745                 0.637526         0.343107\n",
              "nfffb06812158e00    0.882333                 0.945193         0.902666\n",
              "\n",
              "[1714763 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyD42vEP0Hqg"
      },
      "source": [
        "##Test Calc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-1VD3sTnklP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "outputId": "7e55d627-a854-413a-d600-68fc26a1d60e"
      },
      "source": [
        "calc = ScoreCalculator(validation_data, example_preds)\n",
        "# calc.add_predictions_to_validation_df(tournament_preds)\n",
        "# print(calc.compute_corr_with_example_preds(tournament_preds)) # works\n",
        "# print(calc.compute_validation_corr()) # works\n",
        "# print(calc.compute_validation_std())# works\n",
        "# print(calc.compute_feature_exposure()) # works I am choosing to do rank corrilation\n",
        "# print(calc.compute_validation_sharpe()) # works\n",
        "# print(calc.compute_max_drawdown()) # works\n",
        "\n",
        "\n",
        "d = calc.compute_numerai_diagnostics(tournament_preds)\n",
        "d\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>valid_sharpe</th>\n",
              "      <th>valid_corr</th>\n",
              "      <th>valid_SD</th>\n",
              "      <th>feature_exposure</th>\n",
              "      <th>max_drawdown</th>\n",
              "      <th>corr_with_example_preds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.998927</td>\n",
              "      <td>-0.021054</td>\n",
              "      <td>0.026961</td>\n",
              "      <td>0.246548</td>\n",
              "      <td>-0.513604</td>\n",
              "      <td>-0.881295</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   valid_sharpe  valid_corr  ...  max_drawdown  corr_with_example_preds \n",
              "0     -0.998927   -0.021054  ...     -0.513604                 -0.881295\n",
              "\n",
              "[1 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPur43HSyhYu"
      },
      "source": [
        "compute_numerai_diagnostics"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}