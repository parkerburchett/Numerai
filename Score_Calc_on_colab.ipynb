{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Score Calc on colab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fvB7bsbhgAnW",
        "onM80O8sj7j9"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf0mcGT2fzIT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ScoreCalculator:\n",
        "    \"\"\"\n",
        "        Calcuating various metrics on the relationship between your predictions, example predictions and validation data.\n",
        "\n",
        "\n",
        "        Call compute_numerai_diagnostics(a pd.Series of your predictions on the validation data)\n",
        "        \n",
        "\n",
        "        Add method to compute more differnent diagonistcs\n",
        "        \n",
        "        Currently not throughly tested.\n",
        "\n",
        "\n",
        "        Primarily based on: example.py \n",
        "    \"\"\"\n",
        "    def __init__(self, validation_data, example_preds):\n",
        "        self.validation_data = validation_data\n",
        "        self._rank_normalized_validation_targets = validation_data['rank_target'] \n",
        "        self._feature_col_names = [column_name for column_name in self.validation_data.columns if 'feature' in column_name]\n",
        "        self.example_predictions = example_preds\n",
        "        self._rank_normalized_example_predictions = example_preds['rank_example_prediction'] # hardcoded\n",
        "    \n",
        "    def score(self, df: pd.DataFrame)-> float:\n",
        "        \"\"\"\n",
        "          # You should replace with lambda for speed\n",
        "            utility to compute corr on a grouping of self._validation_data \n",
        "        \"\"\"\n",
        "        return _compute_corr(df['rank_target'], df['rank_prediction'])\n",
        "\n",
        "    # suspect\n",
        "    def richards_dependence(self, df, target_col, era_col, prediction_col) -> float: \n",
        "        \"\"\"\n",
        "            Measures the independendence of prediction with the targets\n",
        "            \n",
        "            Currently unused \n",
        "            example call:\n",
        "            richards_dependence(df, 'target', 'era', 'prediction'))\n",
        "            Source: Numerai Forumn user:richai @ https://forum.numer.ai/t/independence-and-sharpe/2560 | May 3 ,2021\n",
        "        \"\"\"  \n",
        "        scores_by_era = df.groupby(era_col).apply(lambda d: d[[prediction_col, target_col]].corr()[target_col][0])\n",
        "            \n",
        "        # these need to be ranked within era so \"error\" makes sense\n",
        "        df[prediction_col] = df.groupby(era_col)[prediction_col].rank(pct=True)\n",
        "        df[target_col] = df.groupby(era_col)[target_col].rank(pct=True)\n",
        "\n",
        "        df[\"era_score\"] = df[era_col].map(scores_by_era)\n",
        "\n",
        "        df[\"error\"] = (df[target_col] - df[prediction_col]) ** 2\n",
        "        df[\"1-error\"] = 1 - df[\"error\"]\n",
        "\n",
        "        # Returns the correlation of the 1-error with the era_score\n",
        "        # i.e. how dependent/correlated each prediction is with its era_score\n",
        "        return df[[\"1-error\", \"era_score\"]].corr()[\"era_score\"][0]\n",
        "\n",
        "\n",
        "    def rank_noramalize_series(self, col:pd.Series)-> pd.Series:\n",
        "        \"\"\"\n",
        "            Compute the rank ordering of col. Scale each element of col between 0 and 1 based on their relative size\n",
        "            Returns: a pd.Series\n",
        "        \"\"\" \n",
        "        scaled_col = (col.rank(method=\"first\") - 0.5) / len(col)\n",
        "        scaled_col.index = col.index\n",
        "        return scaled_col\n",
        "\n",
        " \n",
        "    def compute_validation_corr(self)-> float:\n",
        "        \"\"\"\n",
        "            pred: your predictions on the validation data.\n",
        "            Compute your corr on the validation data.\n",
        "            # need to call add_predictions_to_validation_df() before you call this or it will throw an derror\n",
        "        \"\"\"\n",
        "        ranked_targets = self.validation_data['rank_target']\n",
        "        ranked_preds = self.validation_data['rank_prediction']\n",
        "        return self._compute_corr(ranked_targets, ranked_preds)\n",
        "\n",
        "\n",
        "    def _compute_corr(self, a: pd.Series, b: pd.Series )->float:\n",
        "        \"\"\"\n",
        "            Returns np.corrcoef on a and b. pass this only ranked correlations\n",
        "        \"\"\"\n",
        "        return np.corrcoef(a, b)[0, 1] # not ranked \n",
        "\n",
        "\n",
        "    def compute_validation_std(self) -> float:\n",
        "        \"\"\"\n",
        "            Returns the Standard Deviation of corr by era.\n",
        "            can be made to be more efficient\n",
        "        \"\"\"\n",
        "        return self.validation_data.groupby(\"era\").apply(lambda df: np.corrcoef(df['rank_target'], df['rank_prediction'])[0][1]).std()\n",
        "\n",
        "\n",
        "    def compute_validation_sharpe(self,)-> float:\n",
        "        \"\"\"\n",
        "            Computes your sharpe corr socre on each era \n",
        "            sharpe = average corr by era / std dev of corr by era. I am usign rank_target adn rank_prediction I don't know if that is correct\n",
        "        \"\"\"\n",
        "\n",
        "        # need to comute the c\n",
        "        era_corr_scores = self.validation_data.groupby(\"era\").app([['rank_target','rank_prediction']].corr()\n",
        "\n",
        "\n",
        "        mean_era_scores = era_corr_scores.mean()\n",
        "        std_era_scores = self.compute_validation_std()\n",
        "        return mean_era_scores / std_era_scores\n",
        "        \n",
        "\n",
        "    def compute_max_drawdown(self, pred: pd.Series)-> float:\n",
        "        \"\"\"\n",
        "            Copied from Numerai's example_model.py\n",
        "            Max drawdown is the \"largest cumulative between any two eras in terms of validation correlation\"\n",
        "            Is an estimate of risk\n",
        "        \"\"\"\n",
        "        validation_correlations = self.compute_validation_corr(pred).groupby(\"era\").apply(score) # this needs to be stored in the class variables do avoid doing it twice\n",
        "        rolling_max = (validation_correlations + 1).cumprod().rolling(window=100, min_periods=1).max()\n",
        "                                                                    \n",
        "        daily_value = (validation_correlations + 1).cumprod()\n",
        "        max_drawdown = -(rolling_max - daily_value).max()\n",
        "        return max_drawdown\n",
        "\n",
        "\n",
        "    def compute_feature_exposure(self)-> float:\n",
        "        \"\"\"\n",
        "            The maximum corrilatiosn your predictions have with any single feature\n",
        "            Copied from Numerai's example_model.py\n",
        "        \"\"\"\n",
        "        # pred_valid_df = self.validation_data # unclear if the default to \n",
        "        # pred_valid_df['prediction'] = rank_noramalize_series(pred) # add prediction column\n",
        "\n",
        "        # feature_names = [f for f in self.validation_data.columns if f.startswith(\"feature\")]\n",
        "        # feature_exposures = validation_data[feature_names].apply(lambda d: correlation(pred_valid_df['prediction'], d), axis=0) # axis =0 means by columns\n",
        "        feature_exposures = []\n",
        "        for col in self._feature_col_names:\n",
        "          feature_exposure_for_col = self._compute_corr(self.validation_data[col], self.validation_data['prediction']) # does feature exposrue look at rank corr \n",
        "          feature_exposures.append(feature_exposure_for_col)\n",
        "                                                             \n",
        "        max_feature_exposure = np.max(np.abs(np.array(feature_exposures)))\n",
        "        return max_feature_exposure\n",
        "\n",
        "        # I don't understand this\n",
        "    def compute_feature_neutral_corr_mean(self, pred:pd.Series)-> float:\n",
        "        \"\"\"\n",
        "            The mean of your per era correlation after your predictions have been neutralized to all the features\n",
        "            Copied from Numerai's example_model.py\n",
        "        \"\"\"\n",
        "        pred_valid_df = self.validation_data # unclear if the default to \n",
        "        pred_valid_df['prediction'] = rank_noramalize_series(pred) # add prediction column\n",
        "\n",
        "        feature_cols = [c for c in df.columns if c.startswith(\"feature\")]\n",
        "        pred_valid_df.loc[:, \"neutral_sub\"] = neutralize(pred_valid_df, ['prediction'],\n",
        "                                            feature_cols)['prediction']\n",
        "        \n",
        "        # I the rank normalize within the lambda\n",
        "        scores = df.groupby(\"era\").apply(\n",
        "            lambda x: self._compute_corr(rank_noramalize_series(x[\"neutral_sub\"]), rank_noramalize_series(x['target']))).mean()\n",
        "        return np.mean(scores)\n",
        "\n",
        "    #suspect\n",
        "    def neutralize(self, df, columns, by, proportion=1.0):\n",
        "        \"\"\"\n",
        "            Copied as is from example_model.py\n",
        "        \"\"\"\n",
        "        scores = df.loc[:, columns]\n",
        "        exposures = df[by].values\n",
        "\n",
        "        # constant column to make sure the series is completely neutral to exposures\n",
        "        exposures = np.hstack(\n",
        "            (exposures,\n",
        "            np.asarray(np.mean(scores)) * np.ones(len(exposures)).reshape(-1, 1)))\n",
        "\n",
        "        scores = scores - proportion * exposures.dot(\n",
        "            np.linalg.pinv(exposures).dot(scores))\n",
        "        return scores / scores.std()\n",
        "    \n",
        "    #suspect\n",
        "    def compute_mmc_stats(self, pred:pd.Series) -> tuple:\n",
        "        \"\"\"\n",
        "            Using example predictions as an estimate for the meta model, compute mmc stats\n",
        "            Copied from example_model.py\n",
        "            returns val_mmc_mean, corr_plus_mmc_sharpe, \n",
        "\n",
        "            Not refractored. Copied as is. Only variable and function names are changed\n",
        "\n",
        "        \"\"\"\n",
        "        pred_valid_df = self.validation_data # unclear if the default to \n",
        "        pred_valid_df['prediction'] = rank_noramalize_series(pred) # add prediction column\n",
        "        pred_valid_df['ExamplePreds'] = self.example_predictions\n",
        "        mmc_scores = []\n",
        "        corr_scores = []\n",
        "\n",
        "        for _, x in validation_data.groupby(\"era\"):\n",
        "            series = self.neutralize_series(pd.Series(self.rank_noramalize_series(x['prediction'])),\n",
        "                                    pd.Series(self.rank_noramalize_series(x[\"ExamplePreds\"])))\n",
        "            mmc_scores.append(np.cov(series, x['target'])[0, 1] / (0.29 ** 2))\n",
        "            corr_scores.append(correlation(self.rank_noramalize_series(x['prediction']), x['target']))\n",
        "\n",
        "        val_mmc_mean = np.mean(mmc_scores)\n",
        "        val_mmc_std = np.std(mmc_scores)\n",
        "        val_mmc_sharpe = val_mmc_mean / val_mmc_std\n",
        "        corr_plus_mmcs = [c + m for c, m in zip(corr_scores, mmc_scores)]\n",
        "        corr_plus_mmc_sharpe = np.mean(corr_plus_mmcs) / np.std(corr_plus_mmcs)\n",
        "        corr_plus_mmc_mean = np.mean(corr_plus_mmcs)\n",
        "        #corr_plus_mmc_sharpe_diff = corr_plus_mmc_sharpe - validation_sharpe\n",
        "\n",
        "        # print(\n",
        "        #     f\"MMC Mean: {val_mmc_mean}\\n\"\n",
        "        #     f\"Corr Plus MMC Sharpe:{corr_plus_mmc_sharpe}\\n\"\n",
        "        #     f\"Corr Plus MMC Diff:{corr_plus_mmc_sharpe_diff}\"\n",
        "        # )\n",
        "        return  val_mmc_mean, corr_plus_mmc_sharpe, \n",
        "\n",
        "    #suspect\n",
        "    def neutralize_series(self, series, by, proportion=1.0):\n",
        "        \"\"\"\n",
        "            Copied from example_model.py\n",
        "            not refactored\n",
        "        \"\"\"\n",
        "        scores = series.values.reshape(-1, 1)\n",
        "        exposures = by.values.reshape(-1, 1)\n",
        "\n",
        "        # this line makes series neutral to a constant column so that it's centered and for sure gets corr 0 with exposures\n",
        "        exposures = np.hstack(\n",
        "            (exposures,\n",
        "            np.array([np.mean(series)] * len(exposures)).reshape(-1, 1)))\n",
        "\n",
        "        correction = proportion * (exposures.dot(\n",
        "            np.linalg.lstsq(exposures, scores, rcond=None)[0]))\n",
        "        corrected_scores = scores - correction\n",
        "        neutralized = pd.Series(corrected_scores.ravel(), index=series.index)\n",
        "        return neutralized\n",
        "\n",
        "    \n",
        "    def compute_corr_with_example_preds(self, tournament_pred:pd.DataFrame) -> float:\n",
        "        \"\"\"\n",
        "            Compute the rank corrilation between your tournament_pred and the example predictions\n",
        "            tournament_pred: pd.DataFrame must have 'rank_prediction' column\n",
        "            WORKS \n",
        "        \"\"\"\n",
        "        return self._compute_corr(tournament_pred['rank_prediction'], self._rank_normalized_example_predictions)\n",
        "    \n",
        "      # replace very bad\n",
        "    def merge_pred_valid_df(self,pred: pd.Series) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "            Add your predictions to self.validation_data in order to make calcuating the answers more efficnet \n",
        "        \"\"\"\n",
        "\n",
        "        pred_valid_df = self.validation_data # unclear if the default to \n",
        "        pred_valid_df['prediction'] = rank_noramalize_series(pred)\n",
        "        return pred_valid_df        \n",
        "\n",
        "\n",
        "    def compute_per_era_corr(self, pred: pd.Series) -> list:\n",
        "        \"\"\"\n",
        "            Returns a list of tuples for representing (era, corr for era)\n",
        "        \"\"\"\n",
        "        pred_valid_df = self.merge_pred_valid_df(pred)\n",
        "        era_corr_list = []\n",
        "        eras = list(pred_valid_df['era'].unique())\n",
        "        for era in eras:\n",
        "            local_era_targets = np.array(valid_df[valid_df['era'] == era]['target'])\n",
        "            local_era_predictions = np.array(valid_df[valid_df['era'] == era]['prediction'])\n",
        "            era_corr = self._compute_corr(local_era_targets, local_era_predictions)\n",
        "            era_corr_list.append((era,era_corr))\n",
        "        \n",
        "        return era_corr_list\n",
        "\n",
        "    # this is the main method that you call on your validation predictions\n",
        "    # my_score_calculator = ScoreCalculator()\n",
        "    # scores =my_score_calculator.compute_numerai_diagnostics(my_model.predict(validation_data[features]))\n",
        "    # print(scores)\n",
        "\n",
        "    def add_predictions_to_validation_df(self, tournament_preds:pd.DataFrame):\n",
        "      \"\"\"\n",
        "        updates the self.validation_df with your prediction in tournament_predss\n",
        "\n",
        "        tournament_df: pd.DataFrame Your predictions for this round.\n",
        "\n",
        "        Must have index = 'id'\n",
        "        \n",
        "        Must have column 'prediction' \n",
        "      \"\"\"\n",
        "      valid_ids = self.validation_data.index # get all the ids with the valaidatino data\n",
        "      preds_on_valid_data = tournament_preds.loc[valid_ids,:] # subset on the validation data\n",
        "\n",
        "      self.validation_data['prediction'] = preds_on_valid_data['prediction']\n",
        "      rows = self.validation_data.shape[0]\n",
        "      self.validation_data['rank_prediction'] = self.validation_data['prediction'].rank() / rows\n",
        "\n",
        "\n",
        "    def compute_numerai_diagnostics(self, tournament_preds: pd.Series) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "            Returns a pd.DataFrame that mimics the numerai diagnostics when you submit predictions.\n",
        "\n",
        "            pred is the tournament predictions taht you limit into only the validation prediction # need a limiting method\n",
        "        \"\"\"\n",
        "        diagnostics_df = pd.DataFrame()\n",
        "        self.add_predictions_to_validation_df(tournament_preds)\n",
        "\n",
        "        diagnostics_df['valid_sharpe'] = [self.compute_validation_sharpe(tournament_preds)]\n",
        "        diagnostics_df['valid_corr'] = [self.compute_validation_corr(tournament_preds)]\n",
        "        diagnostics_df['valid_FNC'] = [self.compute_feature_neutral_corr_mean(tournament_preds)]\n",
        "\n",
        "        diagnostics_df['valid_SD'] = [self.compute_validation_std(tournament_preds)]\n",
        "        diagnostics_df['feature_exposure'] = [self.compute_feature_exposure(tournament_preds)]\n",
        "        diagnostics_df['max_drawdown'] = [self.compute_max_drawdown(tournament_preds)]\n",
        "\n",
        "        val_mmc_mean, corr_plus_mmc_sharpe = self.compute_mmc_stats(tournament_preds) # suspect\n",
        "\n",
        "        diagnostics_df['corr_plus_MMC_sharpe'] = [corr_plus_mmc_sharpe]\n",
        "        diagnostics_df['MMC_mean '] = [val_mmc_mean]\n",
        "        # this is broken you need to only look at the same id rows in example preds and\n",
        "        diagnostics_df['corr_with_example_preds '] = [self.compute_corr_with_example_preds(pred)] # works\n",
        "        return diagnostics_df\n",
        "\n"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvB7bsbhgAnW"
      },
      "source": [
        "## Class to ping scores. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G2EHwZVgDZO"
      },
      "source": [
        "class NumeraiDataLoader:\n",
        "  \"\"\"\n",
        "      Pings and cleans the data from Numerai\n",
        "  \"\"\"\n",
        "  def ping_validation_data(self) -> pd.DataFrame:\n",
        "            \"\"\"\n",
        "            Ping Numerai to create get the live tournament data and extact all the validation data.\n",
        "\n",
        "            Adapted from : https://www.kaggle.com/code1110/numerai-tournament | May 3, 2021\n",
        "            \"\"\"\n",
        "            tournament_data_url = 'https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_tournament_data.csv.xz'\n",
        "            tournament_df = pd.read_csv(tournament_data_url)\n",
        "            valid_df = tournament_df[tournament_df[\"data_type\"] == \"validation\"].reset_index(drop = True)\n",
        "            feature_cols = valid_df.columns[valid_df.columns.str.startswith('feature')]\n",
        "\n",
        "            map_floats_to_ints = {0.0 : 0, 0.25 : 1, 0.5 : 2, 0.75 : 3, 1.0 : 4}\n",
        "            for col in feature_cols:\n",
        "                valid_df[col] = valid_df[col].map(map_floats_to_ints).astype(np.uint8) # reduce space costs by casting features as ints\n",
        "                \n",
        "            valid_df[\"era\"] = valid_df[\"era\"].apply(lambda x: int(x[3:])) # strip the word 'era' from the era column\n",
        "            valid_df.drop(columns=[\"data_type\"], inplace=True)\n",
        "\n",
        "            total_valid_rows = valid_df.shape[0]\n",
        "            valid_df['rank_target'] = valid_df['target'].rank(method='first') / total_valid_rows\n",
        "            valid_df.set_index('id', inplace=True)\n",
        "            return valid_df\n",
        "\n",
        "        # called during init # broken You need to specify that this is example preds over the entire df\n",
        "  def ping_example_predictions(self)-> pd.DataFrame:\n",
        "      \"\"\"\n",
        "          Create a dataframe of Id, Prediction, rank_prediction, where Id, is the id column in tournament_data.csv prediction is the numerai provided example model, and rank_prediction is the normalized prediction target\n",
        "         \t                  prediction  rank_prediction\n",
        "          id\t\t\n",
        "          n0003aa52cab36c2\t0.49\t0.097334\n",
        "          n000920ed083903f\t0.49\t0.097335\n",
        "          n0038e640522c4a6\t0.53\t0.969455\n",
        "          n004ac94a87dc54b\t0.51\t0.656894\n",
        "          n0052fe97ea0c05f\t0.50\t0.332613\n",
        "      \"\"\"\n",
        "      example_predictions_url = \"https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_example_predictions_data.csv.xz\"\n",
        "      example_preds =  pd.read_csv(example_predictions_url, index_col=0)\n",
        "      total_example_prediction_rows = example_preds.shape[0]\n",
        "      example_preds['rank_example_prediction'] = example_preds['prediction'].rank(method='first') / total_example_prediction_rows\n",
        "      return example_preds\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onM80O8sj7j9"
      },
      "source": [
        "### tester"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6yVBBx0gce-",
        "outputId": "4e93a263-854d-41a0-8687-e2ad9e86f9f1"
      },
      "source": [
        "myLoader = NumeraiDataLoader()\n",
        "\n",
        "validation_data = myLoader.ping_validation_data()\n",
        "print(validation_data.head())\n",
        "print(validation_data.shape)\n",
        "\n",
        "example_preds = myLoader.ping_example_predictions()\n",
        "print(example_preds.head())\n",
        "print(example_preds.shape)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                  era  feature_intelligence1  ...  target  rank_target\n",
            "id                                            ...                     \n",
            "n0003aa52cab36c2  121                      1  ...    0.25     0.049935\n",
            "n000920ed083903f  121                      3  ...    0.50     0.249755\n",
            "n0038e640522c4a6  121                      4  ...    1.00     0.950058\n",
            "n004ac94a87dc54b  121                      3  ...    0.50     0.249762\n",
            "n0052fe97ea0c05f  121                      1  ...    0.75     0.750223\n",
            "\n",
            "[5 rows x 313 columns]\n",
            "(137779, 313)\n",
            "                  prediction  rank_example_prediction\n",
            "id                                                   \n",
            "n0003aa52cab36c2        0.49                 0.097334\n",
            "n000920ed083903f        0.49                 0.097335\n",
            "n0038e640522c4a6        0.53                 0.969455\n",
            "n004ac94a87dc54b        0.51                 0.656894\n",
            "n0052fe97ea0c05f        0.50                 0.332613\n",
            "(1714763, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ROAYPsPXrghu",
        "outputId": "5e03d123-73ce-4bc1-dad0-7bac9f921f8a"
      },
      "source": [
        "tournament_preds_rows = tournament_preds.shape[0]\n",
        "tournament_preds['rank_prediction'] = tournament_preds['prediction'].rank(method='first') / tournament_preds_rows\n",
        "\n",
        "tournament_preds"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prediction</th>\n",
              "      <th>rank_example_prediction</th>\n",
              "      <th>rank_prediction</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>n0003aa52cab36c2</th>\n",
              "      <td>0.882333</td>\n",
              "      <td>0.995267</td>\n",
              "      <td>0.667388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n000920ed083903f</th>\n",
              "      <td>0.882333</td>\n",
              "      <td>0.995267</td>\n",
              "      <td>0.667389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n0038e640522c4a6</th>\n",
              "      <td>0.862807</td>\n",
              "      <td>0.565749</td>\n",
              "      <td>0.005497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n004ac94a87dc54b</th>\n",
              "      <td>0.872745</td>\n",
              "      <td>0.791893</td>\n",
              "      <td>0.120487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n0052fe97ea0c05f</th>\n",
              "      <td>0.877583</td>\n",
              "      <td>0.945192</td>\n",
              "      <td>0.343107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nffa71c03a5a27a2</th>\n",
              "      <td>0.877583</td>\n",
              "      <td>0.791894</td>\n",
              "      <td>0.667387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nffd391982772aeb</th>\n",
              "      <td>0.877583</td>\n",
              "      <td>0.791893</td>\n",
              "      <td>0.667388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nffda15ceb83f190</th>\n",
              "      <td>0.872745</td>\n",
              "      <td>0.637527</td>\n",
              "      <td>0.343106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nffda7325b750430</th>\n",
              "      <td>0.872745</td>\n",
              "      <td>0.637526</td>\n",
              "      <td>0.343107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nfffb06812158e00</th>\n",
              "      <td>0.882333</td>\n",
              "      <td>0.945193</td>\n",
              "      <td>0.902666</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1714763 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  prediction  rank_example_prediction  rank_prediction\n",
              "id                                                                    \n",
              "n0003aa52cab36c2    0.882333                 0.995267         0.667388\n",
              "n000920ed083903f    0.882333                 0.995267         0.667389\n",
              "n0038e640522c4a6    0.862807                 0.565749         0.005497\n",
              "n004ac94a87dc54b    0.872745                 0.791893         0.120487\n",
              "n0052fe97ea0c05f    0.877583                 0.945192         0.343107\n",
              "...                      ...                      ...              ...\n",
              "nffa71c03a5a27a2    0.877583                 0.791894         0.667387\n",
              "nffd391982772aeb    0.877583                 0.791893         0.667388\n",
              "nffda15ceb83f190    0.872745                 0.637527         0.343106\n",
              "nffda7325b750430    0.872745                 0.637526         0.343107\n",
              "nfffb06812158e00    0.882333                 0.945193         0.902666\n",
              "\n",
              "[1714763 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyD42vEP0Hqg"
      },
      "source": [
        "##Test Calc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "i-1VD3sTnklP",
        "outputId": "6d536b39-2e5f-45d8-e221-e781568a4a77"
      },
      "source": [
        "calc = ScoreCalculator(validation_data, example_preds)\n",
        "calc.add_predictions_to_validation_df(tournament_preds)\n",
        "print(calc.compute_corr_with_example_preds(tournament_preds)) # works\n",
        "print(calc.compute_validation_corr()) # works\n",
        "print(calc.compute_validation_std())# works\n",
        "print(calc.compute_feature_exposure()) # works\n",
        "print(calc.compute_validation_sharpe())\n",
        "# tournament_preds is a dataframe with index =id and at least rank_pred column that is your rank normalized predictions"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.8812945443598307\n",
            "-0.02105413938616274\n",
            "0.02696081000367848\n",
            "0.24654750263199626\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f, data)\u001b[0m\n\u001b[1;32m    891\u001b[0m         \"\"\"\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-a2223817c27f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_validation_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# works\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_feature_exposure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# works\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_validation_sharpe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# tournament_preds is a dataframe with index =id and at least rank_pred column that is your rank normalized predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-86-415623dedeed>\u001b[0m in \u001b[0;36mcompute_validation_sharpe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0msharpe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage\u001b[0m \u001b[0mcorr\u001b[0m \u001b[0mby\u001b[0m \u001b[0mera\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mstd\u001b[0m \u001b[0mdev\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorr\u001b[0m \u001b[0mby\u001b[0m \u001b[0mera\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mI\u001b[0m \u001b[0mam\u001b[0m \u001b[0musign\u001b[0m \u001b[0mrank_target\u001b[0m \u001b[0madn\u001b[0m \u001b[0mrank_prediction\u001b[0m \u001b[0mI\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mknow\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mera_corr_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"era\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_corr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rank_target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rank_prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0mmean_era_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mera_corr_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mstd_era_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_validation_std\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0m_group_selection_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f, data)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \"\"\"\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         return self._wrap_applied_output(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# group might be modified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPur43HSyhYu"
      },
      "source": [
        ""
      ],
      "execution_count": 68,
      "outputs": []
    }
  ]
}