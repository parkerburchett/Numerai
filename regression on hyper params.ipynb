{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from sklearn import preprocessing\r\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['total_time', 'round_number', 'boosting_type', 'class_weight',\n       'colsample_bytree', 'importance_type', 'learning_rate', 'max_depth',\n       'min_child_samples', 'min_child_weight', 'min_split_gain',\n       'n_estimators', 'n_jobs', 'num_leaves', 'objective', 'random_state',\n       'reg_alpha', 'reg_lambda', 'silent', 'subsample', 'subsample_for_bin',\n       'subsample_freq', 'feature_fraction', 'seed', 'correlation',\n       'corr_sharpe', 'corr_mean', 'corr_std', 'max_drawdown',\n       'feature_exposure', 'max_feature_exposure'],\n      dtype='object')"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_scores():\r\n",
    "  df = pd.read_csv('numerai_hyperparams_scores.csv')\r\n",
    "  return df\r\n",
    "df = load_scores()\r\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['learning_rate_n_estimators_product'] = df['learning_rate'] * df['n_estimators']\r\n",
    "df['feature_fraction_learning_rate_ratio'] = df['learning_rate'] / df['feature_fraction']\r\n",
    "independent_variables = ['feature_fraction','n_estimators','learning_rate', 'max_depth','learning_rate_n_estimators_product','feature_fraction_learning_rate_ratio']\r\n",
    "dependent_variables = ['correlation'] # you might want the n_estimators/learning_rate column since that might matter. \r\n",
    "\r\n",
    "def normalize(df, variables):\r\n",
    "    \"\"\"\r\n",
    "        Normalize so that you can properly interperate the coeffiencets impact on correlation and corr_sharpe\r\n",
    "    \"\"\"\r\n",
    "    x = df[variables].values\r\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\r\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\r\n",
    "    return pd.DataFrame(x_scaled, columns=variables)\r\n",
    "    \r\n",
    "independent_variables_df = normalize(df,independent_variables)\r\n",
    "dependent_variables_df =  normalize(df,dependent_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:            correlation   R-squared (uncentered):                   0.895\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.894\n",
      "Method:                 Least Squares   F-statistic:                              1026.\n",
      "Date:                Wed, 21 Apr 2021   Prob (F-statistic):                        0.00\n",
      "Time:                        09:40:04   Log-Likelihood:                         -6.5908\n",
      "No. Observations:                 728   AIC:                                      25.18\n",
      "Df Residuals:                     722   BIC:                                      52.72\n",
      "Df Model:                           6                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "========================================================================================================\n",
      "                                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "feature_fraction                         0.3488      0.036      9.680      0.000       0.278       0.420\n",
      "n_estimators                             1.1811      0.030     39.583      0.000       1.123       1.240\n",
      "learning_rate                            1.0555      0.062     17.006      0.000       0.934       1.177\n",
      "max_depth                                0.4543      0.086      5.303      0.000       0.286       0.622\n",
      "learning_rate_n_estimators_product      -2.3245      0.073    -31.975      0.000      -2.467      -2.182\n",
      "feature_fraction_learning_rate_ratio     0.3640      0.238      1.527      0.127      -0.104       0.832\n",
      "==============================================================================\n",
      "Omnibus:                       47.672   Durbin-Watson:                   1.756\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               58.181\n",
      "Skew:                          -0.598   Prob(JB):                     2.32e-13\n",
      "Kurtosis:                       3.700   Cond. No.                         19.2\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "def compute_regression(dependent_variables_df, independent_variables_df):\r\n",
    "    model = sm.OLS(dependent_variables_df, independent_variables_df)\r\n",
    "    results = model.fit()\r\n",
    "    print(results.summary())\r\n",
    "    \r\n",
    "compute_regression(dependent_variables_df,independent_variables_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_fraction</th>\n      <th>n_estimators</th>\n      <th>learning_rate</th>\n      <th>max_depth</th>\n      <th>learning_rate_n_estimators_product</th>\n      <th>feature_fraction_learning_rate_ratio</th>\n      <th>correlation</th>\n      <th>corr_sharpe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>116.000000</td>\n      <td>116.000000</td>\n      <td>116.000000</td>\n      <td>116.000000</td>\n      <td>116.000000</td>\n      <td>116.000000</td>\n      <td>116.000000</td>\n      <td>116.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.111095</td>\n      <td>2900.000000</td>\n      <td>0.031603</td>\n      <td>3.991379</td>\n      <td>82.206897</td>\n      <td>0.283790</td>\n      <td>0.024632</td>\n      <td>0.952266</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.035221</td>\n      <td>547.881295</td>\n      <td>0.023859</td>\n      <td>0.751760</td>\n      <td>17.272586</td>\n      <td>0.138363</td>\n      <td>0.000483</td>\n      <td>0.029382</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.090000</td>\n      <td>200.000000</td>\n      <td>0.013000</td>\n      <td>3.000000</td>\n      <td>18.000000</td>\n      <td>0.066667</td>\n      <td>0.024100</td>\n      <td>0.905900</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.095000</td>\n      <td>3000.000000</td>\n      <td>0.024000</td>\n      <td>4.000000</td>\n      <td>72.000000</td>\n      <td>0.236364</td>\n      <td>0.024300</td>\n      <td>0.927550</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.105000</td>\n      <td>3000.000000</td>\n      <td>0.028000</td>\n      <td>4.000000</td>\n      <td>84.000000</td>\n      <td>0.263636</td>\n      <td>0.024500</td>\n      <td>0.947900</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>0.115000</td>\n      <td>3000.000000</td>\n      <td>0.032000</td>\n      <td>4.000000</td>\n      <td>93.000000</td>\n      <td>0.305263</td>\n      <td>0.024900</td>\n      <td>0.971200</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>0.380000</td>\n      <td>5000.000000</td>\n      <td>0.248000</td>\n      <td>9.000000</td>\n      <td>120.000000</td>\n      <td>1.411111</td>\n      <td>0.026400</td>\n      <td>1.055200</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "       feature_fraction  n_estimators  learning_rate   max_depth  \\\ncount        116.000000    116.000000     116.000000  116.000000   \nmean           0.111095   2900.000000       0.031603    3.991379   \nstd            0.035221    547.881295       0.023859    0.751760   \nmin            0.090000    200.000000       0.013000    3.000000   \n25%            0.095000   3000.000000       0.024000    4.000000   \n50%            0.105000   3000.000000       0.028000    4.000000   \n75%            0.115000   3000.000000       0.032000    4.000000   \nmax            0.380000   5000.000000       0.248000    9.000000   \n\n       learning_rate_n_estimators_product  \\\ncount                          116.000000   \nmean                            82.206897   \nstd                             17.272586   \nmin                             18.000000   \n25%                             72.000000   \n50%                             84.000000   \n75%                             93.000000   \nmax                            120.000000   \n\n       feature_fraction_learning_rate_ratio  correlation  corr_sharpe  \ncount                            116.000000   116.000000   116.000000  \nmean                               0.283790     0.024632     0.952266  \nstd                                0.138363     0.000483     0.029382  \nmin                                0.066667     0.024100     0.905900  \n25%                                0.236364     0.024300     0.927550  \n50%                                0.263636     0.024500     0.947900  \n75%                                0.305263     0.024900     0.971200  \nmax                                1.411111     0.026400     1.055200  "
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = df[independent_variables + dependent_variables +['corr_sharpe']]\r\n",
    "best_models = summary_df[np.logical_and(summary_df['correlation']>0.024,summary_df['corr_sharpe']>.9)]\r\n",
    "# you need to bound learning rate * n_estimators (betwen 70 and 90)\r\n",
    "best_models.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_fraction</th>\n      <th>n_estimators</th>\n      <th>learning_rate</th>\n      <th>max_depth</th>\n      <th>learning_rate_n_estimators_product</th>\n      <th>feature_fraction_learning_rate_ratio</th>\n      <th>correlation</th>\n      <th>corr_sharpe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>135</th>\n      <td>0.095</td>\n      <td>3000</td>\n      <td>0.031</td>\n      <td>4</td>\n      <td>93.0</td>\n      <td>0.326316</td>\n      <td>0.0264</td>\n      <td>1.0080</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>0.095</td>\n      <td>3000</td>\n      <td>0.028</td>\n      <td>4</td>\n      <td>84.0</td>\n      <td>0.294737</td>\n      <td>0.0259</td>\n      <td>0.9844</td>\n    </tr>\n    <tr>\n      <th>120</th>\n      <td>0.095</td>\n      <td>3000</td>\n      <td>0.028</td>\n      <td>4</td>\n      <td>84.0</td>\n      <td>0.294737</td>\n      <td>0.0259</td>\n      <td>0.9844</td>\n    </tr>\n    <tr>\n      <th>389</th>\n      <td>0.255</td>\n      <td>200</td>\n      <td>0.248</td>\n      <td>4</td>\n      <td>49.6</td>\n      <td>0.972549</td>\n      <td>0.0259</td>\n      <td>1.0004</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>0.095</td>\n      <td>3000</td>\n      <td>0.027</td>\n      <td>4</td>\n      <td>81.0</td>\n      <td>0.284211</td>\n      <td>0.0258</td>\n      <td>1.0030</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0.100</td>\n      <td>3000</td>\n      <td>0.034</td>\n      <td>3</td>\n      <td>102.0</td>\n      <td>0.340000</td>\n      <td>0.0241</td>\n      <td>0.9471</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>0.100</td>\n      <td>3000</td>\n      <td>0.040</td>\n      <td>3</td>\n      <td>120.0</td>\n      <td>0.400000</td>\n      <td>0.0241</td>\n      <td>1.0134</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.095</td>\n      <td>3000</td>\n      <td>0.034</td>\n      <td>3</td>\n      <td>102.0</td>\n      <td>0.357895</td>\n      <td>0.0241</td>\n      <td>0.9171</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.110</td>\n      <td>3000</td>\n      <td>0.032</td>\n      <td>3</td>\n      <td>96.0</td>\n      <td>0.290909</td>\n      <td>0.0241</td>\n      <td>0.9493</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>0.100</td>\n      <td>3000</td>\n      <td>0.025</td>\n      <td>5</td>\n      <td>75.0</td>\n      <td>0.250000</td>\n      <td>0.0241</td>\n      <td>0.9219</td>\n    </tr>\n  </tbody>\n</table>\n<p>116 rows × 8 columns</p>\n</div>",
      "text/plain": "     feature_fraction  n_estimators  learning_rate  max_depth  \\\n135             0.095          3000          0.031          4   \n65              0.095          3000          0.028          4   \n120             0.095          3000          0.028          4   \n389             0.255           200          0.248          4   \n115             0.095          3000          0.027          4   \n..                ...           ...            ...        ...   \n31              0.100          3000          0.034          3   \n46              0.100          3000          0.040          3   \n30              0.095          3000          0.034          3   \n28              0.110          3000          0.032          3   \n156             0.100          3000          0.025          5   \n\n     learning_rate_n_estimators_product  feature_fraction_learning_rate_ratio  \\\n135                                93.0                              0.326316   \n65                                 84.0                              0.294737   \n120                                84.0                              0.294737   \n389                                49.6                              0.972549   \n115                                81.0                              0.284211   \n..                                  ...                                   ...   \n31                                102.0                              0.340000   \n46                                120.0                              0.400000   \n30                                102.0                              0.357895   \n28                                 96.0                              0.290909   \n156                                75.0                              0.250000   \n\n     correlation  corr_sharpe  \n135       0.0264       1.0080  \n65        0.0259       0.9844  \n120       0.0259       0.9844  \n389       0.0259       1.0004  \n115       0.0258       1.0030  \n..           ...          ...  \n31        0.0241       0.9471  \n46        0.0241       1.0134  \n30        0.0241       0.9171  \n28        0.0241       0.9493  \n156       0.0241       0.9219  \n\n[116 rows x 8 columns]"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models.sort_values(by=['correlation'],ascending=False)\r\n",
    "\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit (conda)",
   "name": "python383jvsc74a57bd05f55334c0ec2b6b265735cb6e4e448fe59a4ec2646b0eb29ab8c6a2d945064a9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}