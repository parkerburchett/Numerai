{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "maxDataPoints.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7bWSBkk2_m3h",
        "oSo8yDCxTBB1",
        "z4vmuIio762C",
        "t3RY5VyX8C1w"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parkerburchett/Numerai/blob/main/maxDataPoints.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7atJJ2fMiJ8"
      },
      "source": [
        "# The goal of this notebook is to set up modular ways to test and submit lots of variations on the light Gradient Boost Machine, to the data about them and then be able to identify them later and Identify patterns.\n",
        "\n",
        "Methods needed.\n",
        "\n",
        "1. You need a way to go from a list of hyper params, ( in the all_data_file) to a trained model.\n",
        "2. You need a way to save to disk (or cloud or where ever) the all_stats dict object.\n",
        "3. You need a way ot put this on to any computer and then post that data to a sql database somewhere\n",
        "\n",
        "\n",
        "\n",
        "https://microsoft.github.io/FLAML/\n",
        "\n",
        "You might want to expirment with this library for auto ML tuning\n",
        "\n",
        "https://docs.dask.org/en/latest/\n",
        "this is for distributed computing\n",
        "\n",
        "\n",
        "Pick the range for the hyper paramaters.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Notebook this is based on: \n",
        "https://www.kaggle.com/code1110/numerai-tournament\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0iP-UgesMiKB",
        "outputId": "37dedf33-6e57-4b6d-c65a-74cfcc7507cf"
      },
      "source": [
        "!pip install numerapi\n",
        "import numerapi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting numerapi\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/96/ebdbaff5a2fef49b212e4f40634166f59e45462a768c0136d148f00255c5/numerapi-2.4.5-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from numerapi) (2.8.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from numerapi) (7.1.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from numerapi) (2018.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from numerapi) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.29.1 in /usr/local/lib/python3.7/dist-packages (from numerapi) (4.41.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->numerapi) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->numerapi) (2020.12.5)\n",
            "Installing collected packages: numerapi\n",
            "Successfully installed numerapi-2.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4WFeO-ZMiKC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, sys\n",
        "import gc\n",
        "import pathlib\n",
        "import json\n",
        "import datetime\n",
        "from typing import List, NoReturn, Union, Tuple, Optional, Text, Generic, Callable, Dict\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, QuantileTransformer\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, TimeSeriesSplit\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss, mean_squared_error, mean_absolute_error, f1_score\n",
        "from scipy.stats import spearmanr # -P I think this is corr. \n",
        "import joblib\n",
        "\n",
        "# model\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "import operator\n",
        "\n",
        "# visualize\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.style as style\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.ticker import ScalarFormatter\n",
        "sns.set_context(\"talk\")\n",
        "style.use('seaborn-colorblind')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0ELMvF79l3D",
        "outputId": "87629a7b-12f5-493b-ac8e-50020d45f9e7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b364c12-MiKD"
      },
      "source": [
        "## Methods to Gather and Clean Incoming Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm1stk1pMiKD"
      },
      "source": [
        "def cast_eras_as_int(x): # this is used to cast the eras from strings to ints\n",
        "    try:\n",
        "        return int(x[3:]) # the eras look like era03 or era123\n",
        "    except:\n",
        "        return 1000\n",
        "\n",
        "# unclear if numerapi.download_latest_data() would be faster\n",
        "def read_data(data='train'):\n",
        "    # get data \n",
        "    if data == 'train':\n",
        "        df = pd.read_csv('https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_training_data.csv.xz')\n",
        "\n",
        "        # The test data is significantly larger.\n",
        "        # test data is the live tournment data\n",
        "    elif data == 'test':\n",
        "        df = pd.read_csv('https://numerai-public-datasets.s3-us-west-2.amazonaws.com/latest_numerai_tournament_data.csv.xz')\n",
        "        \n",
        "    \n",
        "    # features\n",
        "    feature_cols = df.columns[df.columns.str.startswith('feature')]\n",
        "    \n",
        "    # map to int, to reduce the memory demand\n",
        "    mapping = {0.0 : 0, 0.25 : 1, 0.5 : 2, 0.75 : 3, 1.0 : 4} # this is very clever -P\n",
        "    for c in feature_cols:\n",
        "        df[c] = df[c].map(mapping).astype(np.uint8)\n",
        "        \n",
        "    df[\"era\"] = df[\"era\"].apply(cast_eras_as_int)# also cast era to int\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6qoKn7W4Za_"
      },
      "source": [
        "### Load the Data from Numerai"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyKw25FmMiKD",
        "outputId": "c8175afa-4100-4adb-aa4f-7a31a8134ae8"
      },
      "source": [
        "%%time\n",
        "# load in the Training data\n",
        "train_data = read_data('train')\n",
        "print(train_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(501808, 314)\n",
            "CPU times: user 1min 24s, sys: 4.87 s, total: 1min 29s\n",
            "Wall time: 1min 31s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOiCNwHGMiKE",
        "outputId": "ea69bad8-e40f-45e1-bc76-dee00094b08e"
      },
      "source": [
        "%%time\n",
        "# the testing data is the tournament data. There is validation data in this column\n",
        "# takes like 10 minutes to run.\n",
        "tournament_data = read_data('test')\n",
        "print(tournament_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1693046, 314)\n",
            "CPU times: user 5min 8s, sys: 26.3 s, total: 5min 34s\n",
            "Wall time: 5min 41s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "strAzqc-MiKE"
      },
      "source": [
        "### Extract the Validation from the tournament_data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD9w9dCYMiKF",
        "outputId": "55c4e7af-ce5b-4fbc-8ca2-784f948bcb2e"
      },
      "source": [
        "# validation is derived from the live tournament data\n",
        "valid = tournament_data[tournament_data[\"data_type\"] == \"validation\"].reset_index(drop = True) # when the data_type == Validation that means there is already a target for those vectors.\n",
        "# those are the last spot check on the model's vectors \n",
        "print(valid.columns) # valid is a df where\n",
        "# validation split\n",
        "# valid.loc[valid[\"era\"] > 180, \"valid2\"] = True # Every era after 180 is in validation\n",
        "# valid.loc[valid[\"era\"] <= 180, \"valid2\"] = False # Every era before is not in the validation set. \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['id', 'era', 'data_type', 'feature_intelligence1',\n",
            "       'feature_intelligence2', 'feature_intelligence3',\n",
            "       'feature_intelligence4', 'feature_intelligence5',\n",
            "       'feature_intelligence6', 'feature_intelligence7',\n",
            "       ...\n",
            "       'feature_wisdom38', 'feature_wisdom39', 'feature_wisdom40',\n",
            "       'feature_wisdom41', 'feature_wisdom42', 'feature_wisdom43',\n",
            "       'feature_wisdom44', 'feature_wisdom45', 'feature_wisdom46', 'target'],\n",
            "      dtype='object', length=314)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qG2TlTRy_7OU"
      },
      "source": [
        "### Drop Data_type_column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l_BqycKMiKF",
        "outputId": "eddc1d35-8d2f-4ab2-e256-69295d090aff"
      },
      "source": [
        "# remove data_type to save memory\n",
        "train_data.drop(columns=[\"data_type\"], inplace=True)\n",
        "valid.drop(columns=[\"data_type\"], inplace=True) #\n",
        "tournament_data.drop(columns=[\"data_type\"], inplace=True)\n",
        "print('The number of records: train {:,}, test {:,}'.format(train_data.shape[0], tournament_data.shape[0])) # df.shape[0] is number of rows."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of records: train 501,808, test 1,693,046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AiydLA2MiKG"
      },
      "source": [
        "## Determine features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "box2-PgOMiKG"
      },
      "source": [
        "FEATURES = [f for f in tournament_data.columns.values.tolist() if 'feature' in f] # Column Names that contains 'feature'\n",
        "TARGET = tournament_data.columns[tournament_data.columns.str.startswith('target')].values.tolist()[0] # the string 'target'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4khTMbONzW-"
      },
      "source": [
        "### ModelStats Object\n",
        "\n",
        "1. Stores the Trained Model\n",
        "2. Stores the Hyper Parameters\n",
        "3. Stores the Validation Scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LCuE_km4Y_3"
      },
      "source": [
        "class ModelStats():\n",
        "  \"\"\"\n",
        "  An object that tracks Hyper parmas, Time Costs and Scores. \n",
        "  Use this to track your the relationship between hyper paramters training time, and \n",
        "  \"\"\"\n",
        "  def __init__(self, model, scores:dict, total_time):\n",
        "        self.model = model # A Trained Model. Look into memory problems\n",
        "        self.hyperparams = model.get_params() # dictionary of hyper params used to train the model\n",
        "        self.scores = scores # dictionary of the CORR Scores. From score_summary().\n",
        "        self.total_time = total_time\n",
        "        self.all_stats_dict = None # untested. \n",
        "\n",
        "\n",
        "  def create_all_stats_dict(self):\n",
        "    \"\"\"\n",
        "    In order to do Hyper Parameter tuning. I need to convert this model into a array of values. \n",
        "    \"\"\"\n",
        "    if self.all_stats_dict == None:\n",
        "      DECIMALS = 4 # how many decimals do you want to track. 4 is good enough I think. \n",
        "      all_stats_dict = {}\n",
        "      all_stats_dict['total_time'] = self.total_time\n",
        "      all_stats_dict.update(self.hyperparams)\n",
        "      all_stats_dict.update(self.scores)\n",
        "\n",
        "      for key in all_stats_dict.keys():\n",
        "          try:\n",
        "            all_stats_dict[key] = round(all_stats_dict[key],DECIMALS)# make more readable\n",
        "          except:\n",
        "            all_stats_dict[key] = all_stats_dict[key]\n",
        "\n",
        "      self.all_stats_dict = all_stats_dict\n",
        "\n",
        "\n",
        "  def headlines(self):\n",
        "    \"\"\"\n",
        "    # Get a subset of scores that are the high level summary of the model\n",
        "    \"\"\"\n",
        "    self.create_all_stats_dict()\n",
        "    summary_dict = {}\n",
        "    summary_dict['correlation'] = self.all_stats_dict['correlation']\n",
        "    summary_dict['corr_sharpe'] = self.all_stats_dict['corr_sharpe']\n",
        "    summary_dict['max_depth'] = self.all_stats_dict['max_depth']\n",
        "    summary_dict['n_estimators'] = self.all_stats_dict['n_estimators']\n",
        "    summary_dict['boosting_type'] = self.all_stats_dict['boosting_type']\n",
        "    summary_dict['total_time'] = self.all_stats_dict['total_time']  \n",
        "    summary_dict['num_leaves'] = self.all_stats_dict['num_leaves']\n",
        "    summary_dict['learning_rate'] = self.all_stats_dict['learning_rate']\n",
        "    return summary_dict\n",
        "    \n",
        "\n",
        "def train_LGBMRegressor(params: dict, train_data): # there is not really a clear cell to put this method\n",
        "  \"\"\"\n",
        "  Inputs: a dict of hyper paramaters for the model, \n",
        "  train_data: a pd.DataFrame of the training Data\n",
        "\n",
        "  Returns a trained model based on the parmas\n",
        "  \"\"\"\n",
        "  model = lgb.LGBMRegressor(**params) \n",
        "  model.fit(train_data[FEATURES], train_data[TARGET])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bWSBkk2_m3h"
      },
      "source": [
        "#### Methods to Determine Validation Scores\n",
        "\n",
        "1. I did not write these. I added the English comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szXbJM0mMiKJ"
      },
      "source": [
        "# naming conventions\n",
        "PREDICTION_NAME = 'prediction'\n",
        "TARGET_NAME = TARGET # 'target is the string named 'target'\n",
        "# EXAMPLE_PRED = 'example_prediction'\n",
        "\n",
        "# ---------------------------\n",
        "# Functions\n",
        "# ---------------------------\n",
        "def valid4score(valid : pd.DataFrame, pred : np.ndarray, load_example: bool=True, save : bool=False) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generate new valid pandas dataframe for computing scores\n",
        "    \n",
        "    :INPUT:\n",
        "    - valid : pd.DataFrame extracted from tournament data (data_type='validation')\n",
        "    \n",
        "    \"\"\"\n",
        "    valid_df = valid.copy() # the validation dataframe you use this to test the CORR and other values\n",
        "\n",
        "    # Your model creates an array of floats [0,1] rank method converst them in a list of ints. \n",
        "\n",
        "    # your lis tof ints is then compared to their list of ints. \n",
        "    valid_df['prediction'] = pd.Series(pred).rank(pct=True, method=\"first\") # pred is the array of predictions your model creates for the set of validation vectors.  \n",
        "    # I am unsure if this preds is a float only only between 0,1,2,3,4. \n",
        "    valid_df.rename(columns={TARGET: 'target'}, inplace=True)\n",
        "    \n",
        "    # I don't know what the load example boolean is. I think you can use this to save predictions.\n",
        "    if load_example:\n",
        "        valid_df[EXAMPLE_PRED] = pd.read_csv(EXP_DIR + 'valid_df.csv')['prediction'].values\n",
        "    \n",
        "    if save==True:\n",
        "        valid_df.to_csv(OUTPUT_DIR + 'valid_df.csv', index=False)\n",
        "        print('Validation dataframe saved!')\n",
        "    \n",
        "    return valid_df\n",
        "\n",
        "def compute_corr(valid_df : pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Compute rank correlation\n",
        "\n",
        "    THIS IS WHAT YOU ARE PRIMARILY PAID ON \n",
        "    \n",
        "    :INPUT:\n",
        "    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n",
        "    \n",
        "    \"\"\"\n",
        "    # this uses Person Correilation. \n",
        "    # I You are paid on spearman corrilation. That is where the ratio of change is important not the raw amount of change\n",
        "    # see: https://support.minitab.com/en-us/minitab-express/1/help-and-how-to/modeling-statistics/regression/supporting-topics/basics/a-comparison-of-the-pearson-and-spearman-correlation-methods/\n",
        "    return np.corrcoef(valid_df[\"target\"], valid_df['prediction'])[0, 1]\n",
        "\n",
        "def compute_max_drawdown(validation_correlations : pd.Series):\n",
        "    \"\"\"\n",
        "    Compute max drawdown\n",
        "    \n",
        "    :INPUT:\n",
        "    - validation_correaltions : pd.Series\n",
        "    \"\"\"\n",
        "    \n",
        "    rolling_max = (validation_correlations + 1).cumprod().rolling(window=100, min_periods=1).max()\n",
        "    daily_value = (validation_correlations + 1).cumprod()\n",
        "    max_drawdown = -(rolling_max - daily_value).max()\n",
        "    \n",
        "    return max_drawdown\n",
        "\n",
        "def compute_val_corr(valid_df : pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Compute rank correlation for valid periods\n",
        "    \n",
        "    :INPUT:\n",
        "    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n",
        "    \"\"\"\n",
        "    \n",
        "    # all validation\n",
        "    correlation = compute_corr(valid_df)\n",
        "    #print(\"rank corr = {:.4f}\".format(correlation))\n",
        "    return correlation\n",
        "    \n",
        "def compute_val_sharpe(valid_df : pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Compute sharpe ratio for valid periods\n",
        "    \n",
        "    :INPUT:\n",
        "    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n",
        "    \"\"\"\n",
        "    # all validation\n",
        "    d = valid_df.groupby('era')[['target', 'prediction']].corr().iloc[0::2,-1].reset_index()\n",
        "    me = d['prediction'].mean()\n",
        "    sd = d['prediction'].std()\n",
        "    max_drawdown = compute_max_drawdown(d['prediction'])\n",
        "    #print('sharpe ratio = {:.4f}, corr mean = {:.4f}, corr std = {:.4f}, max drawdown = {:.4f}'.format(me / sd, me, sd, max_drawdown))\n",
        "    \n",
        "    return me / sd, me, sd, max_drawdown\n",
        "    \n",
        "def feature_exposures(valid_df : pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Compute feature exposure\n",
        "    \n",
        "    :INPUT:\n",
        "    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n",
        "    \"\"\"\n",
        "    feature_names = [f for f in valid_df.columns\n",
        "                     if f.startswith(\"feature\")]\n",
        "    exposures = []\n",
        "    for f in feature_names:\n",
        "        fe = spearmanr(valid_df['prediction'], valid_df[f])[0]\n",
        "        exposures.append(fe)\n",
        "    return np.array(exposures)\n",
        "\n",
        "def max_feature_exposure(fe : np.ndarray):\n",
        "    return np.max(np.abs(fe))\n",
        "\n",
        "def feature_exposure(fe : np.ndarray):\n",
        "    return np.sqrt(np.mean(np.square(fe)))\n",
        "\n",
        "def compute_val_feature_exposure(valid_df : pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Compute feature exposure for valid periods\n",
        "    \n",
        "    :INPUT:\n",
        "    - valid_df : pd.DataFrame where at least 2 columns ('prediction' & 'target') exist\n",
        "    \"\"\"\n",
        "    # all validation\n",
        "    fe = feature_exposures(valid_df)\n",
        "    fe1, fe2 = feature_exposure(fe), max_feature_exposure(fe)\n",
        "    #print('feature exposure = {:.4f}, max feature exposure = {:.4f}'.format(fe1, fe2))\n",
        "     \n",
        "    return fe1, fe2\n",
        "\n",
        "# to neutralize a column in a df by many other columns\n",
        "#         I have no idea what this method does. -P. need to read about it and write up a link to it. \n",
        "def neutralize(df, columns, by, proportion=1.0):\n",
        "    scores = df.loc[:, columns]\n",
        "    exposures = df[by].values\n",
        "\n",
        "    # constant column to make sure the series is completely neutral to exposures\n",
        "    exposures = np.hstack(\n",
        "        (exposures,\n",
        "         np.asarray(np.mean(scores)) * np.ones(len(exposures)).reshape(-1, 1)))\n",
        "\n",
        "    scores = scores - proportion * exposures.dot(\n",
        "        np.linalg.pinv(exposures).dot(scores))\n",
        "    return scores / scores.std()\n",
        "\n",
        "\n",
        "# to neutralize any series by any other series\n",
        "def neutralize_series(series, by, proportion=1.0):\n",
        "    scores = series.values.reshape(-1, 1)\n",
        "    exposures = by.values.reshape(-1, 1)\n",
        "\n",
        "    # this line makes series neutral to a constant column so that it's centered and for sure gets corr 0 with exposures\n",
        "    exposures = np.hstack(\n",
        "        (exposures,\n",
        "         np.array([np.mean(series)] * len(exposures)).reshape(-1, 1)))\n",
        "\n",
        "    correction = proportion * (exposures.dot(\n",
        "        np.linalg.lstsq(exposures, scores, rcond=None)[0]))\n",
        "    corrected_scores = scores - correction\n",
        "    neutralized = pd.Series(corrected_scores.ravel(), index=series.index)\n",
        "    return neutralized\n",
        "\n",
        "\n",
        "def unif(df):\n",
        "    x = (df.rank(method=\"first\") - 0.5) / len(df)\n",
        "    return pd.Series(x, index=df.index)\n",
        "\n",
        "def get_feature_neutral_mean(df):\n",
        "    feature_cols = [c for c in df.columns if c.startswith(\"feature\")]\n",
        "    df.loc[:, \"neutral_sub\"] = neutralize(df, [PREDICTION_NAME],\n",
        "                                          feature_cols)[PREDICTION_NAME]\n",
        "    scores = df.groupby(\"era\").apply(\n",
        "        lambda x: np.corrcoef(x[\"neutral_sub\"].rank(pct=True, method=\"first\"), x[TARGET_NAME])).mean()\n",
        "    return np.mean(scores)\n",
        "\n",
        "def compute_val_mmc(valid_df : pd.DataFrame):    \n",
        "    # MMC over validation\n",
        "    mmc_scores = []\n",
        "    corr_scores = []\n",
        "    for _, x in valid_df.groupby(\"era\"):\n",
        "        series = neutralize_series(pd.Series(unif(x[PREDICTION_NAME])),\n",
        "                                   pd.Series(unif(x[EXAMPLE_PRED])))\n",
        "        mmc_scores.append(np.cov(series, x[TARGET_NAME])[0, 1] / (0.29 ** 2)) # I have no idea what htis line does (0.29 ** 2)\n",
        "        corr_scores.append(np.corrcoef(unif(x[PREDICTION_NAME]).rank(pct=True, method=\"first\"), x[TARGET_NAME]))\n",
        "\n",
        "    val_mmc_mean = np.mean(mmc_scores)\n",
        "    val_mmc_std = np.std(mmc_scores)\n",
        "    val_mmc_sharpe = val_mmc_mean / val_mmc_std\n",
        "    corr_plus_mmcs = [c + m for c, m in zip(corr_scores, mmc_scores)]\n",
        "    corr_plus_mmc_sharpe = np.mean(corr_plus_mmcs) / np.std(corr_plus_mmcs)\n",
        "    corr_plus_mmc_mean = np.mean(corr_plus_mmcs)\n",
        "\n",
        "    #print(\"MMC Mean = {:.6f}, MMC Std = {:.6f}, CORR+MMC Sharpe = {:.4f}\".format(val_mmc_mean, val_mmc_std, corr_plus_mmc_sharpe))\n",
        "\n",
        "    # Check correlation with example predictions\n",
        "    corr_with_example_preds = np.corrcoef(valid_df[EXAMPLE_PRED].rank(pct=True, method=\"first\"),\n",
        "                                          valid_df[PREDICTION_NAME].rank(pct=True, method=\"first\"))[0, 1]\n",
        "    #print(\"Corr with example preds: {:.4f}\".format(corr_with_example_preds))\n",
        "    \n",
        "    return val_mmc_mean, val_mmc_std, corr_plus_mmc_sharpe, corr_with_example_preds\n",
        "\n",
        "\n",
        "# this is the main method. The rest are just called interanlly. \n",
        "def score_summary(valid_df : pd.DataFrame):\n",
        "    score_dict = {}\n",
        "    \n",
        "    try:\n",
        "        score_dict['correlation'] = compute_val_corr(valid_df)\n",
        "    except:\n",
        "        print('ERR: computing correlation')\n",
        "    try:\n",
        "        score_dict['corr_sharpe'], score_dict['corr_mean'], score_dict['corr_std'], score_dict['max_drawdown'] = compute_val_sharpe(valid_df)\n",
        "    except:\n",
        "        print('ERR: computing sharpe')\n",
        "    try:\n",
        "        score_dict['feature_exposure'], score_dict['max_feature_exposure'] = compute_val_feature_exposure(valid_df)\n",
        "    except:\n",
        "        print('ERR: computing feature exposure')\n",
        "    # try:\n",
        "    #     score_dict['mmc_mean'], score_dict['mmc_std'], score_dict['corr_mmc_sharpe'], score_dict['corr_with_example_xgb'] = compute_val_mmc(valid_df)\n",
        "    # except:\n",
        "    #     print('ERR: computing MMC')\n",
        "    \n",
        "    return score_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lBD0oUmBWzx"
      },
      "source": [
        "### Main to train and track time, hyper parmas and scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80k6-VBtBWhf"
      },
      "source": [
        "def train_validate_store(params, train_data, validation_data,features):\n",
        "  \"\"\"\n",
        "  Train a model, get validation scores, create a Model_Stats Object.\n",
        "  \"\"\"\n",
        "  start_time = datetime.datetime.now()\n",
        "  my_model = train_LGBMRegressor(params=params, train_data=train_data)\n",
        "  my_predictions = my_model.predict(validation_data[features])\n",
        "  valid_df = valid4score(validation_data, my_predictions, load_example=False, save=False)\n",
        "  my_scores = score_summary(valid_df)\n",
        "  total_time = (datetime.datetime.now() - start_time).total_seconds() # untested\n",
        "  my_model_stats = ModelStats(model=my_model, scores=my_scores,total_time=total_time)\n",
        "  return my_model_stats \n",
        "\n",
        "def save_my_model_stats(ModelStatsObject):\n",
        "  # best is just to cast it as a list. and append it to the file in your google drive\n",
        "  # establish Gdrive connetction. \n",
        "  # convert values to a list of tupeles.\n",
        "  # look at file. If no header:\n",
        "    #add header based on alphabeticly sorted list of col names.\n",
        "  # .append (stats.values())\n",
        "  return 0\n",
        "              "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maQAdU1L2scH"
      },
      "source": [
        "### Conclustions:\n",
        "\n",
        "Basic tests show n_estimators, num_leaves follow a basic pattern of sharpe increase then pleateuing out\n",
        "\n",
        "Now testign estimators at 30k learning rate at .001 and leave in increments of 5. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-BMAUwM8Dpp"
      },
      "source": [
        "saving_all_stats =[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf0BRd77fZMA"
      },
      "source": [
        "# Testing some theories. \n",
        "\n",
        "Lets keep all but 1 variable constant and then create a Dataframe of all the scores for that changing variable.\n",
        "\n",
        "\n",
        "To start set n_estiamtors =1000 and try all the leaves between 2, and 32. \n",
        "\n",
        "save results to a dataframe.\n",
        "\n",
        "You need to let this run for like 30 minutes. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The validation df might be a constant You might need to only make it once at set up and then just reference it each time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQM5saclfXq6",
        "outputId": "6444d330-48dd-4730-f879-03944dd852ea"
      },
      "source": [
        "%%time\n",
        "param_set = [ {\n",
        "            'n_estimators': 1000,\n",
        "            'objective': 'regression',\n",
        "            'boosting_type': 'gbdt',\n",
        "            'max_depth': 4, # best max depth is 4\n",
        "            'learning_rate': .032,#.032 is best with sharpe >1 and depth =4\n",
        "            'feature_fraction': .095, # MIGHT BE WRONG. NEED TO DOUBLE CHECK. \n",
        "            'seed': i \n",
        "              } for i in range(1,20)] \n",
        "\n",
        "all_scores_rf = []\n",
        "\n",
        "\n",
        "for param in param_set: # this is fully parralizeable \n",
        "  model_stats =  train_validate_store(param,\n",
        "                             train_data=train_data,\n",
        "                             validation_data=valid,\n",
        "                             features=FEATURES)\n",
        "  headlines = model_stats.headlines() # this also gets creates the all_stats_dict\n",
        "  print(model_stats.all_stats_dict)\n",
        "  all_scores_rf.append(model_stats.all_stats_dict)\n",
        "  saving_all_stats.append(model_stats.all_stats_dict) # use this for later r\n",
        "  # you should just write all the stat dicts to a dictionary that you store in main memory. \n",
        "  # while you run these tests. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'total_time': 332.7463, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.032, 'max_depth': 4, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 3000, 'n_jobs': -1, 'num_leaves': 31, 'objective': 'regression', 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 1, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.36, 'seed': 1, 'correlation': 0.0221, 'corr_sharpe': 0.8758, 'corr_mean': 0.0226, 'corr_std': 0.0259, 'max_drawdown': -0.0544, 'feature_exposure': 0.0662, 'max_feature_exposure': 0.2651}\n",
            "{'total_time': 337.3581, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.032, 'max_depth': 4, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 3000, 'n_jobs': -1, 'num_leaves': 31, 'objective': 'regression', 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 1, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.36, 'seed': 2, 'correlation': 0.0227, 'corr_sharpe': 0.8836, 'corr_mean': 0.0231, 'corr_std': 0.0261, 'max_drawdown': -0.0571, 'feature_exposure': 0.0651, 'max_feature_exposure': 0.2597}\n",
            "{'total_time': 323.6893, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.032, 'max_depth': 4, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 3000, 'n_jobs': -1, 'num_leaves': 31, 'objective': 'regression', 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 1, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.36, 'seed': 3, 'correlation': 0.0219, 'corr_sharpe': 0.8751, 'corr_mean': 0.0224, 'corr_std': 0.0256, 'max_drawdown': -0.0501, 'feature_exposure': 0.0659, 'max_feature_exposure': 0.2625}\n",
            "{'total_time': 324.8912, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.032, 'max_depth': 4, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 3000, 'n_jobs': -1, 'num_leaves': 31, 'objective': 'regression', 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 1, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.36, 'seed': 4, 'correlation': 0.0222, 'corr_sharpe': 0.9163, 'corr_mean': 0.0226, 'corr_std': 0.0247, 'max_drawdown': -0.0514, 'feature_exposure': 0.0663, 'max_feature_exposure': 0.2657}\n",
            "{'total_time': 338.2816, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.032, 'max_depth': 4, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 3000, 'n_jobs': -1, 'num_leaves': 31, 'objective': 'regression', 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 1, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.36, 'seed': 5, 'correlation': 0.0222, 'corr_sharpe': 0.9309, 'corr_mean': 0.0226, 'corr_std': 0.0242, 'max_drawdown': -0.0448, 'feature_exposure': 0.0659, 'max_feature_exposure': 0.2634}\n",
            "{'total_time': 333.3172, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.032, 'max_depth': 4, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 3000, 'n_jobs': -1, 'num_leaves': 31, 'objective': 'regression', 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 1, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.36, 'seed': 6, 'correlation': 0.0233, 'corr_sharpe': 0.8993, 'corr_mean': 0.0237, 'corr_std': 0.0264, 'max_drawdown': -0.0539, 'feature_exposure': 0.0667, 'max_feature_exposure': 0.2646}\n",
            "{'total_time': 335.3882, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.032, 'max_depth': 4, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 3000, 'n_jobs': -1, 'num_leaves': 31, 'objective': 'regression', 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 1, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.36, 'seed': 7, 'correlation': 0.0226, 'corr_sharpe': 0.9517, 'corr_mean': 0.023, 'corr_std': 0.0241, 'max_drawdown': -0.0412, 'feature_exposure': 0.0655, 'max_feature_exposure': 0.2614}\n",
            "{'total_time': 329.7933, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.032, 'max_depth': 4, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 3000, 'n_jobs': -1, 'num_leaves': 31, 'objective': 'regression', 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 1, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.36, 'seed': 8, 'correlation': 0.023, 'corr_sharpe': 0.9248, 'corr_mean': 0.0235, 'corr_std': 0.0254, 'max_drawdown': -0.0443, 'feature_exposure': 0.066, 'max_feature_exposure': 0.2636}\n",
            "{'total_time': 328.8793, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.032, 'max_depth': 4, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 3000, 'n_jobs': -1, 'num_leaves': 31, 'objective': 'regression', 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 1, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.36, 'seed': 9, 'correlation': 0.0231, 'corr_sharpe': 0.9563, 'corr_mean': 0.0236, 'corr_std': 0.0247, 'max_drawdown': -0.0435, 'feature_exposure': 0.0663, 'max_feature_exposure': 0.2654}\n",
            "CPU times: user 3h 8min 52s, sys: 15.7 s, total: 3h 9min 7s\n",
            "Wall time: 49min 44s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTW50gG3SJRq"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzYVx_K5TSAe",
        "outputId": "03126b30-2de8-45ae-9ddf-d3d069864bfc"
      },
      "source": [
        "len(saving_all_stats)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "KZGvNy_hg_ri",
        "outputId": "3650176c-4f01-4684-8fe0-f2d3dba5b783"
      },
      "source": [
        "all_scores_df = pd.DataFrame(all_scores_rf) # untested. might be broken\n",
        "all_scores_df.to_csv('/content/drive/MyDrive/allstats3.csv',index=False)\n",
        "all_scores_df.head(50) # you might want to see the derative of each of these variables with repect to the independent.\n",
        "\n",
        "y = all_scores_df.correlation\n",
        "x = all_scores_df.seed\n",
        "plt.plot(x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8c886fc1d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkNvSL6xMKut",
        "outputId": "4365bd8e-ebe9-434b-9d7a-3335d16ef6e9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSh7xmz7lrLk"
      },
      "source": [
        "y = all_scores_df.correlation\n",
        "x = all_scores_df.max_depth\n",
        "plt.plot(x,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsRJSpJNMiKQ"
      },
      "source": [
        "# Submit to Numerai\n",
        "\n",
        "\n",
        "1. Create a prediction list.\n",
        "2. Link those predictions with the tournment data\n",
        "3. Write the id, prediction to a csv file.\n",
        "4. Use numerai wrapper to submit that .csv file as your current model. \n",
        "5. This submits for MRQUANTSALOT and TUTMODEL\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSo8yDCxTBB1"
      },
      "source": [
        "### Methods to handle submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoYEwqg4MiKQ"
      },
      "source": [
        "def load_api_creds_into_dict(): # works\n",
        "  \"\"\"\n",
        "    Read creds.json and return a dictionary of your API keys.\n",
        "  \"\"\"\n",
        "  creds  = open('creds.json','r') # refactor this to point at your google drive. \n",
        "  api_keys_dict = json.load(creds)\n",
        "  creds.close()\n",
        "  return api_keys_dict\n",
        "\n",
        "\n",
        "def open_api_access(): # works\n",
        "    \"\"\"\n",
        "    Read in my private key from creds.json and return the numerai api wrapper\n",
        "    \"\"\"\n",
        "    api_keys_dict = load_api_creds_into_dict()\n",
        "    my_secret_key = api_keys_dict['secret_key']\n",
        "    my_public_id = api_keys_dict['public_id']\n",
        "    napi = numerapi.NumerAPI(secret_key=my_secret_key, public_id=my_public_id)\n",
        "    return napi\n",
        "\n",
        "\n",
        "def create_id_prediction_df(tournament_data: pd.DataFrame, model_predictions : np.ndarray): # works\n",
        "    \"\"\"\n",
        "    Create a dataframe that looks like \n",
        "    id,prediction\n",
        "    asdfads,.5429\n",
        "    asdfaddsss,.5051\n",
        "    ...\n",
        "    \"\"\"\n",
        "    predictions_df = tournament_data[\"id\"].to_frame() # get all the Ids and cast them to a Dataframe\n",
        "    predictions_df[PREDICTION_NAME] = model_predictions #add your predictions to the id frame\n",
        "    return predictions_df # data frame of id, prediction\n",
        "\n",
        "\n",
        "def write_predictions_to_file(prediction_df: pd.DataFrame): # works\n",
        "    my_file_name = 'myPredictions.csv'\n",
        "    try:\n",
        "      out_location = open(my_file_name, 'x')\n",
        "    except:\n",
        "      out_location = open(my_file_name, 'w')\n",
        "\n",
        "    prediction_df.to_csv(out_location, index=False)\n",
        "    out_location.close()\n",
        "    return my_file_name \n",
        "\n",
        "\n",
        "def run_model_and_create_prediction_file(model_object, tournament_data: pd.DataFrame, features: list):\n",
        "  \"\"\"\n",
        "    This stitches everything together.\n",
        "\n",
        "    Pass it a trained model and the tournament data set, the list of feature columns\n",
        "    1. Does preditions\n",
        "    2. write the predictions to a file.\n",
        "    3. returns the name fo the file where my predictions are saved data is saved\n",
        "  \"\"\"\n",
        "  model_predictions = model_object.predict(tournament_data[features])\n",
        "  prediction_df = create_id_prediction_df(tournament_data,model_predictions)\n",
        "  file_with_predictions = write_predictions_to_file(prediction_df)\n",
        "  return file_with_predictions\n",
        "\n",
        "\n",
        "def submit_predictions_to_numerai(filename_of_predictions, sumbit_model_id):\n",
        "    napi = open_api_access() # open a connection to the numerai API with your creds.json file\n",
        "    submission_id = napi.upload_predictions(filename_of_predictions, model_id=sumbit_model_id)\n",
        "    print(f'You successfully submitted for {sumbit_model_id}')\n",
        "    print(type(submission_id))\n",
        "    return submission_id\n",
        "\n",
        "print('your helper methods work correctly')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54YIKJia7TNa"
      },
      "source": [
        "api_keys_dict = load_api_creds_into_dict()\n",
        "mrquantsalot_model_id = api_keys_dict['mr_quants_model_id']\n",
        "tut_model_model_id = api_keys_dict['tutmodel_model_id']\n",
        "PREDICTION_NAME = \"prediction\" # this is the header of the csv file you are creating\n",
        "OUTPUT_DIR = '' # just the root of your local folder in this instance of google colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4vmuIio762C"
      },
      "source": [
        "### Run and submit MRQUANTSALOT\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8FKXKURMiKR"
      },
      "source": [
        "%%time\n",
        "if want_to_submit:\n",
        "  mr_quants_file_with_predictions = run_model_and_create_prediction_file(mr_quants_model, tournament_data, features)\n",
        "  numerai_submission_id_mrQ = submit_predictions_to_numerai(mr_quants_file_with_predictions, mrquantsalot_model_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3RY5VyX8C1w"
      },
      "source": [
        "### Run and submit TUT_MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygq0jiVE8Cg0"
      },
      "source": [
        "%%time\n",
        "if want_to_submit:\n",
        "  tut_model_file_with_predictions = run_model_and_create_prediction_file(tut_model, tournament_data, features)\n",
        "  numerai_submission_id_tut = submit_predictions_to_numerai(tut_model_file_with_predictions, tut_model_model_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3aOmG--eQjt"
      },
      "source": [
        "## The params I am using now. No clear reason for these over another model. \n",
        "\n",
        "Default num_leaves =31\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rROXr1jBOvrg",
        "outputId": "524a2ccd-d024-4ffd-e8cd-89a309e13cb9"
      },
      "source": [
        "param_set = [{\n",
        "            'n_estimators': 500*i,\n",
        "            'objective': 'regression',\n",
        "            'boosting_type': 'gbdt',\n",
        "            'max_depth': 4, # max depth of each random forest\n",
        "            'learning_rate': 0.013, # the size of the step between trees\n",
        "            'feature_fraction': 0.095, # what % of features each tree will consider. you should root this at sqrt(310)/ 310 ~0.058\n",
        "            'seed': 42 # a random seed.\n",
        "            }for i in range(30,60,5)]\n",
        "\n",
        "# i expect overfitting as the n_estimatros gets larger so the sharpe and correlatino scores will go down after this point. \n",
        "\n",
        "# so far is matching thesroy. \n",
        "\n",
        "#~ 5k estimators seems about right.\n",
        "\n",
        "\n",
        "# tut_parmas = {\n",
        "#             'n_estimators': 3000,\n",
        "#             'objective': 'regression',\n",
        "#             'boosting_type': 'gbdt',\n",
        "#             'max_depth': 4,\n",
        "#             'learning_rate': 0.013, \n",
        "#             'feature_fraction': 0.095,\n",
        "#             'seed': 42\n",
        "#             } \n",
        "\n",
        "\n",
        "# this version of the param gets CORR = .0255 and a sharpe of .97\n",
        "for param in param_set: # this is fully parralizeable \n",
        "  model_stats =  train_validate_store(param,\n",
        "                             train_data=train_data,\n",
        "                             validation_data=valid,\n",
        "                             features=FEATURES)\n",
        "  headlines = model_stats.headlines() # this also gets creates the all_stats_dict\n",
        "  print(model_stats.all_stats_dict)\n",
        "  all_scores.append(model_stats.all_stats_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'total_time': 255.1076, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.013, 'max_depth': 4, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 5500, 'n_jobs': -1, 'num_leaves': 31, 'objective': 'regression', 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 1, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.095, 'seed': 42, 'correlation': 0.0255, 'corr_sharpe': 0.9774, 'corr_mean': 0.0259, 'corr_std': 0.0265, 'max_drawdown': -0.0573, 'feature_exposure': 0.0747, 'max_feature_exposure': 0.2652}\n",
            "{'total_time': 359.9538, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.013, 'max_depth': 4, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 8000, 'n_jobs': -1, 'num_leaves': 31, 'objective': 'regression', 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 1, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.095, 'seed': 42, 'correlation': 0.0243, 'corr_sharpe': 0.9753, 'corr_mean': 0.0247, 'corr_std': 0.0253, 'max_drawdown': -0.046, 'feature_exposure': 0.0702, 'max_feature_exposure': 0.2697}\n",
            "{'total_time': 479.5853, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.013, 'max_depth': 4, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 10500, 'n_jobs': -1, 'num_leaves': 31, 'objective': 'regression', 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 1, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.095, 'seed': 42, 'correlation': 0.0233, 'corr_sharpe': 0.9334, 'corr_mean': 0.0238, 'corr_std': 0.0255, 'max_drawdown': -0.048, 'feature_exposure': 0.067, 'max_feature_exposure': 0.2685}\n",
            "{'total_time': 590.3642, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.013, 'max_depth': 4, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 13000, 'n_jobs': -1, 'num_leaves': 31, 'objective': 'regression', 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 1, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.095, 'seed': 42, 'correlation': 0.0226, 'corr_sharpe': 0.8951, 'corr_mean': 0.023, 'corr_std': 0.0257, 'max_drawdown': -0.0515, 'feature_exposure': 0.0656, 'max_feature_exposure': 0.2727}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}